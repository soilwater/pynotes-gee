[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PyNotes GEE",
    "section": "",
    "text": "Introduction\n“PyNotes GEE” is a guide for agricultural professionals, environmental scientists, graduate students, and data enthusiasts looking to leverage the power of Python in conjunction with Google Earth Engine (GEE) to make better data-driven decisions, and understand and manage our planet’s agricultural resources.\nGoogle Earth Engine is an advanced cloud-based platform designed for petabyte-scale analysis of geospatial data, particularly satellite imagery. It provides a comprehensive set of tools for analyzing and visualizing data, facilitating the extraction of meaningful insights from the Earth’s surface over time. The powerful computing infrastructure behind GEE allows researchers to execute complex geospatial analyses that would be computationally intensive or infeasible on conventional laptops and desktop computers. Through its accessible interface, GEE enables automated processing pipelines using Python.\nThrough a series of short, practical, and step-by-step tutorials in the form of Jupyter notebooks, this compendium provides a comprehensive toolkit describing common techniques for extracting, processing, and analyzing Earth data using Python libraries like Xarray, Numpy, Pandas, Matplotlib, GeoPandas. The content is aimed at learners that are familiar with the Python programming language, but are just getting started with Google Earth Engine.\nIf you find any mistakes in the code or have suggestions for other tutorials, please create an issue in the Github repository"
  },
  {
    "objectID": "index.html#getting-started-with-google-earth-engine-gee",
    "href": "index.html#getting-started-with-google-earth-engine-gee",
    "title": "PyNotes GEE",
    "section": "Getting Started with Google Earth Engine (GEE)",
    "text": "Getting Started with Google Earth Engine (GEE)\nThe Google Earth Engine platform can be used with two programming languages: Javascript and Python. This entire series of tutorials is based solely in the Python programming language.\nFirst and foremost, here are two relevant links to the Google Earth Engine official documentation:\n\nMain Google Earth Engine website\nDeveloper Guides\n\n\nPython environemnt\nIf you do not have Python installed in you machine, download the Anaconda package, which includes a ton of curated Python libraries for data science.\n\n\nOther required packages\nThe tutorials were developed with the Anaconda package in mind, however, some tutorial make use of additional libraries. Use the command pip install &lt;package_name&gt; to add the following packages:\n\nfolium: Library for creating interactive maps.\nrasterio: Library for raster data analysis.\ngeopandas: Extends the pandas library to allow spatial operations particularly for vector data.\n\nYou can try to install the packages in one go using: pip install folium rasterio geopandas\n\n\nGEE Account Setup:\n\nCreate a Google Account: If you don’t have one already, sign up for a Google Account.\nJoin Google Earth Engine: Visit the Google Earth Engine website and register for commercial or non-commercial use (free for academic and research use).\nProject Creation: Once your access is approved, create a new project in the Google Developers Console.\n\n\n\nAuthentication:\n\nInstall the Earth Engine Python API: Use pip install earthengine-api to install the Earth Engine Python API.\nOpen a new Jupyter notebook and import the Google Earth Engine module using import ee. We will do this at the beginning of each tutorial.\nAuthenticate with Earth Engine: Run ee.Authenticate() and follow the instructions to authenticate your account.\n\n\n\nOther resources:\nawesome-gee-community-catalog: Community-driven catalog of GEE datasets.\ngeemap: This is an outstanding and comprehensive set of tutorials for those that want a ready-to-use, well-documented, and hassle-free module with tons of videos.\nLeafmap: A library built on folium for spatial analysis and interactive mapping int he notebook.\ncartoee: Library for creating publication quality figures."
  },
  {
    "objectID": "intro.html#basic-concepts-of-geographic-information-systems",
    "href": "intro.html#basic-concepts-of-geographic-information-systems",
    "title": "1  Basic concepts",
    "section": "Basic concepts of geographic information systems",
    "text": "Basic concepts of geographic information systems\nVector Data: represents geographic features as discrete points, lines, and polygons. This format is used to capture details with precise boundaries and locations. For example:\n\nPoints could represent locations such as weather stations, wells, or trees.\nLines might delineate features like rivers, roads, or railway tracks.\nPolygons are used to define areas such as lakes, watersheds, or agricultural fields.\n\nVector data is advantageous for mapping features that have clear boundaries and for tasks that require precise measurements (like distance, perimeter, or area).\nRaster Data: Raster data, on the other hand, is a grid of cells (or pixels), where each cell contains a value representing information, such as temperature, elevation, or land cover. The raster format is effective for representing continuous phenomena. Raster data is often used in: - Satellite imagery, where each pixel has spectral data values. - Digital elevation models (DEMs), where each pixel represents ground elevation. - Thematic maps, such as precipitation or land use maps, where each pixel’s value corresponds to a specific category or quantity.\nRaster data is especially useful for analyzing spatial variations across a region and for modeling environmental and earth surface processes."
  },
  {
    "objectID": "intro.html#geojson",
    "href": "intro.html#geojson",
    "title": "1  Basic concepts",
    "section": "GeoJSON",
    "text": "GeoJSON\nGeoJSON is a light-weight and widely used open standard format designed for representing geographical features. It is based on JSON (JavaScript Object Notation), which is very much like a Python dictionary, making it easy to read and parse by both humans and machines.\nA GeoJSON supports various geometric types such as Point, LineString, Polygon, MultiPoint, MultiLineString, MultiPolygon, and GeometryCollection. Each geometry can also contain properties in the form of key-value pairs, allowing for the addition non-spatial attributes associated with the geographic features.\nThe following example is a Feature Collection showing the GeoJSON data obtained from GEE for two counties. The keys on the very left (columns, features, id, properties, type, and version) are keys of the Feature Collection. Note that the features key has a list of dictionaries as its value. These two dictinaries contain the information for each county. Since each county is a dictionary, then they also have key-value pairs, like geometry, id, properties, and type. This information is repeated in each item. If you look further, you will notice that even the geometry key has another dictionary inside, which contains the coordinates and the type of the geometry.\nCertainly there are multiple levels and quite a bit of nesting, but the information has a clear, organized, and human-readable structure.\n\n\n\n\n\n\nTip\n\n\n\nThe secret to understand GeoJSON objects is to pay attention to:\n\nindentation,\nthe opening { and closing } curly braces,\nopening [ and closing ] square brackets, and\nthe commas , that separate individual structures.\n\n\n\nThe .getInfo() method in GEE allows you to print this information for any object in the notebook. You can also use the Pretty Print (pprint) module in Python to ensure the data is displayed clearly, like the example below. This tutorial will help you get started.\n{'columns': {'ALAND': 'Long',\n             'AWATER': 'Long',\n             'COUNTYFP': 'String',\n             'NAME': 'String',\n             'STATEFP': 'String',\n             'system:index': 'String'},\n 'features': [{'geometry': {'coordinates': [[[-100.9542311520017,36.57269908219634],\n                                             [-100.95409647655981,36.557977388454546],\n                                             [-100.95409647655981,36.557842673053706],\n                                             ...]],\n                            'type': 'Polygon'},\n               'id': '00000000000000000515',\n               'properties': {'ALAND': 4700042738,\n                              'AWATER': 7347161,\n                              'COUNTYFP': '007',\n                              'NAME': 'Beaver',\n                              'NAMELSAD': 'Beaver County',\n                              'STATEFP': '40'},\n               'type': 'Feature'},\n              {'geometry': {'coordinates': [[[-100.0038723945186,36.75510474601957],\n                                             [-100.00382751270251,36.75353381242449],\n                                             [-100.00382751270251,36.75223223032575],\n                                             ...]],\n                            'type': 'Polygon'},\n               'id': '00000000000000000957',\n               'properties': {'ALAND': 2691041230,\n                              'AWATER': 5259447,\n                              'COUNTYFP': '059',\n                              'NAME': 'Harper',\n                              'NAMELSAD': 'Harper County',\n                              'STATEFP': '40'},\n               'type': 'Feature'}],\n 'id': 'TIGER/2016/Counties',\n 'properties': {'date_range': [1451606400000, 1483315200000],\n                'description': 'The United States Census Bureau TIGER dataset '\n                               'contains the 2016 boundaries\\n'\n                               'for primary legal divisions of US states...',\n                'period': 0,\n                'title': 'TIGER: US Census Counties 2016'},\n 'type': 'FeatureCollection',\n 'version': 1566851207937615}"
  },
  {
    "objectID": "intro.html#google-earth-building-blocks",
    "href": "intro.html#google-earth-building-blocks",
    "title": "1  Basic concepts",
    "section": "Google Earth building blocks",
    "text": "Google Earth building blocks\nGoogle Earth Engine (GEE) is a powerful platform for analyzing geospatial data at scale, providing a vast library of satellite imagery and geospatial datasets. The fundamental data structures of GEE are: geometries, features, feature collections, images, and image collections. Understanding these structures is key to effectively utilizing GEE for any geospatial data analysis task.\n\nGeometries\nGeometries represent the simplest form of spatial data in GEE, describing points or shapes in geographic space. They can be points, lines, polygons, or even more complex shapes defining areas (e.g., a rectangle, a watershed, a county), routes, or specific locations on Earth’s surface.\n\n\nFeatures\nA Feature in GEE is a geometry with associated properties. These properties can be metadata or attributes related to the geometry, such as the name of a location, its population, a label, or any other characteristic. Features combine spatial and descriptive information, making them useful for detailed geospatial analyses.\n\n\n\nGeometry and Feature\n\n\n\n\nFeature Collections\nA Feature Collection is a group of features aggregated into a single data structure. This collection can represent a series of points, such as weather stations, or complex combinations of polygons, such as administrative boundaries, each with their own set of attributes. Feature Collections are instrumental in managing and analyzing related sets of features.\n\n\n\nFeatureCollection\n\n\n\n\nImages\nAn Image in GEE is a raster data structure, representing Earth data in grid format where each cell has a value. These images can depict various types of data, such as satellite imagery, temperature maps, elevation data, or derived indices (e.g., NDVI for vegetation analysis). An image may contain multiple bands, with each band representing a different dataset or time snapshot.\n\n\n\nImage\n\n\n\n\nImage Collections\nAn Image Collection is a series of images grouped together, typically representing the same area over time. This could be a sequence of satellite images capturing changes throughout the seasons or years, or a collection of derived datasets like monthly precipitation maps. Image Collections enable temporal analyses and change detection studies over large geographic areas.\n\n\n\nImageCollection\n\n\n\n\nCommonalities and Differences\n\nSpatial Representation: Geometries and Features represent vector data, while Images represent raster data. Feature Collections aggregate vector data, and Image Collections aggregate raster data.\nData Complexity: Geometries are the simplest, defining only shapes. Features add descriptive data to geometries. Images and Image Collections introduce the complexity of raster data, allowing for detailed analysis over discrete units of space and time\nAnalysis Capabilities: Features and Feature Collections are ideal for analyses that require descriptive data alongside spatial data. Images and Image Collections are suited for pixel-based analyses and time-series studies.\n\n\n\nSummary\nLet’s summarize these concepts:\n\nGeometries: Basic shapes (point, line, polygon).\nFeatures: Shapes with associated properties (metadata) like names and unique identifiers.\nFeature Collections: Aggregated features.\nImages: Grid of values (raster), single band or multiple bands.\nImage Collections: Series of related images over time."
  },
  {
    "objectID": "notebooks/colormaps.html#pre-defined-colormaps",
    "href": "notebooks/colormaps.html#pre-defined-colormaps",
    "title": "2  Colormaps",
    "section": "Pre-defined colormaps",
    "text": "Pre-defined colormaps\nLet’s explore how to get a colormap, how to visualize them, how to reverse a colormap, and how to get a reduced version with fewer colors.\n\n# Divergent colormap good for representing soil moisture conditions\ncolormaps.get_cmap('RdBu') # Red-Blue\n\nRdBu  underbad over \n\n\n\n# Increasing colormap good for representing sand or soil organic carbon  \ncolormaps.get_cmap('YlOrBr') # Yellow-Orange-Brown\n\nYlOrBr  underbad over \n\n\n\n# Monochrome colormaps\ncolormaps.get_cmap('Greens') # Can also try Reds, Blues\n\nGreens  underbad over \n\n\n\n# Discrete colormap good for representing categorical variables,\n# like soil textural classes.\ncolormaps.get_cmap('Set1')\n\nSet1  underbad over \n\n\n\n# Reverse a colormap with \"_r\" (run code again removing \"_r\")\ncolormaps.get_cmap('Spectral_r')\n\nSpectral_r  underbad over \n\n\n\n# Get number of colors in colormap\nprint(colormaps.get_cmap('Spectral').N)\n\n256\n\n\n\n# Resample to select fewer colors\ncolormaps.get_cmap('Spectral').resampled(10)\n\nSpectral  underbad over \n\n\n\n# Access single color\n\n# First save the colormap into a variable\ncmap = colormaps.get_cmap('Spectral').resampled(10)\n\n# Explore cmap data type (note that this is not a list)\nprint(type(cmap))\n\n# Access the first color\nprint(cmap(0))\n\n# Access the fifth color\nprint(cmap(4))\n\n# Access the last color\nprint(cmap(cmap.N))\n\n&lt;class 'matplotlib.colors.LinearSegmentedColormap'&gt;\n(0.6196078431372549, 0.00392156862745098, 0.25882352941176473, 1.0)\n(0.9978213507625272, 0.9324618736383442, 0.6357298474945533, 1.0)\n(0.3686274509803922, 0.30980392156862746, 0.6352941176470588, 1.0)\n\n\nNote that the outputs of the colormap are on a scale of 0 to 1 rather than on a scale 0 to 255. Representing RGB colors using the 0 to 1 scale enables a more precise specification of color values, simpler calculations for gradients and blending of colors, compatibility with libraries, and a more intuitive represention of the scale of a given color (easier to understand that 0 to 1 than 0 to 255)."
  },
  {
    "objectID": "notebooks/colormaps.html#rgb-to-hex",
    "href": "notebooks/colormaps.html#rgb-to-hex",
    "title": "2  Colormaps",
    "section": "RGB to HEX",
    "text": "RGB to HEX\nAs mentioned earlier, we need to pass colormaps in the HEX system to GEE. Let’s practice this.\n\n# Get colormap from Matplotlib\nrgb_cmap = colormaps.get_cmap('magma')\n\n# Define number of colors \nn = 7 # Use rgb_cmap.N for all the colors\n\n# Split the cmap \"n\" colors. Here we create the index values\nrgb_index = np.linspace(0, rgb_cmap.N-1, n).astype(int)\n\n# Create a list of HEX colors\nhex_cmap = [colors.rgb2hex(rgb_cmap(k)) for k in rgb_index]\n\nprint(hex_cmap)\n\n['#000004', '#2c115f', '#721f81', '#b5367a', '#f1605d', '#feae77', '#fcfdbf']"
  },
  {
    "objectID": "notebooks/colormaps.html#create-a-helper-function",
    "href": "notebooks/colormaps.html#create-a-helper-function",
    "title": "2  Colormaps",
    "section": "Create a helper function",
    "text": "Create a helper function\nThis will be handy to re-use our code in other tutorials or projects.\n\n# Define function to retrieve colormaps\ndef get_hex_cmap(name,n=10):\n    \"\"\"\n    Function to get list of HEX colors from a Matplotlib colormap.\n    \"\"\"\n    rgb_cmap = colormaps.get_cmap(name)\n    if n &gt; rgb_cmap.N-1:\n        raise ValueError(f\"You select {n} colors, but {name} colormap only has {rgb_cmap.N} colors.\")\n    else:\n        rgb_index = np.linspace(0, rgb_cmap.N-1, n).astype(int)\n        hex_cmap = [colors.rgb2hex(rgb_cmap(k)) for k in rgb_index]\n        return hex_cmap \n\n\n# Test function\nget_hex_cmap('Set1', n=7)\n\n['#e41a1c', '#377eb8', '#4daf4a', '#ff7f00', '#ffff33', '#a65628', '#999999']"
  },
  {
    "objectID": "notebooks/colormaps.html#hex-to-rgb-colors",
    "href": "notebooks/colormaps.html#hex-to-rgb-colors",
    "title": "2  Colormaps",
    "section": "HEX to RGB colors",
    "text": "HEX to RGB colors\nThis conversion sometimes becomes necessary for leveraging Python libraries, such as Rasterio, to generate local maps. For example, when consulting GEE documentation to construct a vegetation index map, you will probably encounter colormaps specified in HEX format. This assumes the use of GEE’s plotting tools. However, to employ the same colormap with alternative Python libraries that operate in the RGB color system, a conversion from HEX to RGB can be useful.\n\n# Paletter of colors for the Enhanced Vegetation Index\nhex_palette = ['#FEFEFE','#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901',\n             '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01',\n             '#012E01', '#011D01', '#011301']\n\n# Use the built-in ListedColormap function to do the conversion\nrgb_cmap = colors.ListedColormap(hex_palette)\n\n\n# Display our new colormap\nrgb_cmap\n\nfrom_list  underbad over"
  },
  {
    "objectID": "notebooks/colormaps.html#rgb-and-hex-in-more-depth",
    "href": "notebooks/colormaps.html#rgb-and-hex-in-more-depth",
    "title": "2  Colormaps",
    "section": "RGB and HEX in more depth",
    "text": "RGB and HEX in more depth\nIf you made this far, let’s delve into a greater level of detail about the RGB and HEX color systems.\nThe RGB color space specifies colors using three components: red, green, and blue, each varying from 0 to 255, or occasionally from 0 to 1 as demonstrated by Matplotlib’s output.\nIn contrast, the HEX system employs six-digit hexadecimal numbers preceded by a hash (#), with each digit pair denoting the red, green, and blue components. For example, white is expressed as (255, 255, 255) in RGB and #ffffff in HEX. Consequently, the RGB system offers 256 intensity levels per component, totaling over 16 million possible colors (256^3 = 16.7 million).\nLet’s look at some examples. Green is depicted as (0, 255, 0) or (0, 1, 0) in RGB and as #00ff00 in HEX. Here, 00 signifies the minimum intensity, while ff denotes the maximum intensity. So ff is equivalent to 255 or 1. Utilizing ten numeric (0 to 9) and six alphabetic (a through f) characters results in 16 alphanumeric digits. Given that \\sqrt{256} = 16, two characters are required to represent 256 combinations, with 00 for 0, 01 for 1, and so forth until fe for 254, and ff for 255.\n\n# Recall our description of the HEX system above.\n# Show that the first color (index zero) \"#FEFEFE\" is (254, 254, 254)\n\nprint('Scale 0-1:', np.array(rgb_cmap(0)))\nprint('Scale 0-255:', (np.array(rgb_cmap(0))*255).astype(int))\n\n# The alpha channel does not have any transparency, so it has a value of 1 or 255\n\nScale 0-1: [0.99607843 0.99607843 0.99607843 1.        ]\nScale 0-255: [254 254 254 255]"
  },
  {
    "objectID": "notebooks/value_at_a_point.html#example-1-elevation",
    "href": "notebooks/value_at_a_point.html#example-1-elevation",
    "title": "3  Value at a point",
    "section": "Example 1: Elevation",
    "text": "Example 1: Elevation\nIn the following example we will retrieve the elevation for a specific point on Earth.\nProduct: USGS/SRTMGL1_003\n\n# Define geographic coordinates\nlat = 39.186512 # This is y\nlon = -96.576844 # This is x\n\n# Convert coordinates into a Point geometry following the x,y notation\npoint = ee.Geometry.Point([lon, lat])\n\n# Explore point geometry\npoint.getInfo()\n\n{'type': 'Point', 'coordinates': [-96.576844, 39.186512]}\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn this tutorial we will use the .getInfo() method to print the underlying data and metadata of multiple objects, so that you can see the output and become more familiar with GEE data structures and the geoJSON format. This information is also valubale for debugging code errors. However, you don’t typically want to clutter your notebooks with these long outputs, so we will skip some of these steps in future tutorials.\n\n\n\n# Load digital elevation model (DEM) from Shuttle Radar Topography Mission (SRTM) \ndem = ee.Image('USGS/SRTMGL1_003')\n\n\n# Obtain some information about the DEM layer (output is long!)\npprint(dem.getInfo())\n\n\n# Retrieve the elevation value: This step will get us close to the answer, but we are not there yet\npprint(dem.sample(point, 1).getInfo())\n\n{'columns': {'elevation': 'Short'},\n 'features': [{'geometry': None,\n               'id': '0',\n               'properties': {'elevation': 317},\n               'type': 'Feature'}],\n 'properties': {'band_order': ['elevation']},\n 'type': 'FeatureCollection'}\n\n\n\n# Retrieve the elevation value: This step will get us even closer to the answer, but we are not there yet\ndem.sample(point, 1).first().getInfo()\n\n{'type': 'Feature',\n 'geometry': None,\n 'id': '0',\n 'properties': {'elevation': 317}}\n\n\n\n# Retrieve the elevation value: This step will get us the correct value\nelev = dem.sample(point, 1).first().getNumber('elevation').getInfo()\nprint(f'Elevation: {elev} m')\n\nElevation: 317 m"
  },
  {
    "objectID": "notebooks/value_at_a_point.html#example-2-weather-variables",
    "href": "notebooks/value_at_a_point.html#example-2-weather-variables",
    "title": "3  Value at a point",
    "section": "Example 2: Weather variables",
    "text": "Example 2: Weather variables\nObtain the long-term mean annual air temperature and precipitation for a specific location\nProduct: For more information about bands and units visit: WorldClim BIO\n\n# Define geographic coordinates\nlat = 39.186512 # This is y\nlon = -96.576844 # This is x\n\n# Convert coordinates into a Point geometry following the x,y notation\npoint = ee.Geometry.Point(lon, lat)\n\n\n# Load WorldClim BIO dataset\ndataset = ee.Image('WORLDCLIM/V1/BIO')\n\n\n# Access metadata of the product (output is long!)\ndataset.getInfo()\n\n\n# Get long-term mean annual air temperature\nT_mean = dataset.select('bio01').sample(point,1).first().getNumber('bio01').multiply(0.1).getInfo()\nprint(f'Mean annual air temperature: {round(T_mean,1)} Celsius')\n\nMean annual air temperature: 12.2 Celsius\n\n\n\n# Get long-term annual precipitation\nP_annual = dataset.select('bio12').sample(point,1).first().get('bio12').getInfo()\nprint(f'Mean annual precipitation: {round(P_annual,1)} mm')\n\nMean annual precipitation: 857 mm"
  },
  {
    "objectID": "notebooks/value_at_a_point.html#example-3-reference-et",
    "href": "notebooks/value_at_a_point.html#example-3-reference-et",
    "title": "3  Value at a point",
    "section": "Example 3: Reference ET",
    "text": "Example 3: Reference ET\nIn this example we will retrieve daily values of reference evapotranspiration for a point.\nProduct: For more information visit the description in Google Earth Engine of GRIDMET\n\n# Define point\npoint = ee.Geometry.Point([-96.576844, 39.186512])\n\n\n# Obtain GRIDMET dataset for a specific period. End date is excluded from the call\nstart_date = ee.Date('2022-07-01')\nend_date = ee.Date('2022-07-02')\nday_of_interest = ee.Date('2022-03-15')\ndataset = ee.ImageCollection('IDAHO_EPSCOR/GRIDMET').filterDate(start_date, end_date)\n\n\n# Information about image collection\npprint(dataset.getInfo())\n\n\n# Use the get methog to retrieve a specific property\ndataset.get('description').getInfo()\n\n\n# Information about first image within the collection (output is long!)\ndataset.first().getInfo()\n\n\n# Information about feature collection\ndataset.first().sample(point,1).getInfo() # Sample at 1 meter resolution\n\n{'type': 'FeatureCollection',\n 'columns': {'bi': 'Float',\n  'erc': 'Float',\n  'eto': 'Float',\n  'etr': 'Float',\n  'fm100': 'Float',\n  'fm1000': 'Float',\n  'pr': 'Float',\n  'rmax': 'Float',\n  'rmin': 'Float',\n  'sph': 'Float',\n  'srad': 'Float',\n  'th': 'Float',\n  'tmmn': 'Float',\n  'tmmx': 'Float',\n  'vpd': 'Float',\n  'vs': 'Float'},\n 'properties': {'band_order': ['pr',\n   'rmax',\n   'rmin',\n   'sph',\n   'srad',\n   'th',\n   'tmmn',\n   'tmmx',\n   'vs',\n   'erc',\n   'eto',\n   'bi',\n   'fm100',\n   'fm1000',\n   'etr',\n   'vpd']},\n 'features': [{'type': 'Feature',\n   'geometry': None,\n   'id': '0',\n   'properties': {'bi': 0,\n    'erc': 20,\n    'eto': 4.5,\n    'etr': 5.300000190734863,\n    'fm100': 14.899999618530273,\n    'fm1000': 17.799999237060547,\n    'pr': 43.70000076293945,\n    'rmax': 90.9000015258789,\n    'rmin': 60.20000076293945,\n    'sph': 0.014340000227093697,\n    'srad': 249.39999389648438,\n    'th': 114,\n    'tmmn': 293.70001220703125,\n    'tmmx': 300.1000061035156,\n    'vpd': 0.7300000190734863,\n    'vs': 2.799999952316284}}]}\n\n\n\n# Information about feature\neto = dataset.first().sample(point,1).first().getNumber('eto').getInfo()\nprint(f'The grass reference ET is {eto} mm')\n\nThe grass reference ET is 4.400000095367432 mm\n\n\nAlternative solution: Access the image directly rather than the collection.\nee.Image('IDAHO_EPSCOR/GRIDMET/20220701').sample(point,1).first().getNumber('eto').getInfo()\n\nGet dataset timestamps\n\n# Obtain the START time of the dataset to check that it matches our request.\n# Response is in milliseconds since 1-Jan-1970\ndataset.select('eto').first().getNumber('system:time_start').getInfo()\n\n1656655200000\n\n\n\n# Obtain the END time of the dataset to check that it matches our request.\n# Response is in milliseconds since 1-Jan-1970\ndataset.select('eto').first().getNumber('system:time_end').getInfo()\n\n1656741600000\n\n\n\n# Find the datetime of the serial date numbers\n# Input in \"fromtimestamp()\" has to be in seconds, so we divide by 1000\nprint('Start time:', datetime.fromtimestamp(1656655200000/1000).strftime('%Y-%m-%d %H:%M:%S.%f'))\nprint('End time:', datetime.fromtimestamp(1656741600000/1000).strftime('%Y-%m-%d %H:%M:%S.%f'))\n\nStart time: 2022-07-01 01:00:00.000000\nEnd time: 2022-07-02 01:00:00.000000"
  },
  {
    "objectID": "notebooks/value_at_a_point.html#example-4-retrieve-soil-properties-for-a-given-location",
    "href": "notebooks/value_at_a_point.html#example-4-retrieve-soil-properties-for-a-given-location",
    "title": "3  Value at a point",
    "section": "Example 4: Retrieve soil properties for a given location",
    "text": "Example 4: Retrieve soil properties for a given location\nProduct: SoilGrids\nSource: https://samapriya.github.io/awesome-gee-community-datasets/projects/isric/\n\n# Load the SoilGrids dataset from GEE\nsoil_grids = ee.Image(\"projects/soilgrids-isric/sand_mean\")\n\n\n# Define a point geometry\nlat = 37.839154\nlon = -99.101594\npoint = ee.Geometry.Point(lon,lat)\nsand = soil_grids.sample(point,250).first().getNumber('sand_0-5cm_mean').multiply(0.1).getInfo()\n\n\nprint(f'The percentage of sand at ({lat},{lon}) is: {round(sand)} %')\n\nThe percentage of sand at (37.839154,-99.101594) is: 53 %"
  },
  {
    "objectID": "notebooks/value_at_multiple_points.html#load-gee-datasets",
    "href": "notebooks/value_at_multiple_points.html#load-gee-datasets",
    "title": "4  Value for multiple points",
    "section": "Load GEE datasets",
    "text": "Load GEE datasets\n\n# Load the SoilGrids dataset from GEE\nsoilgrids_sand = ee.Image(\"projects/soilgrids-isric/sand_mean\")\nsoilgrids_clay = ee.Image(\"projects/soilgrids-isric/clay_mean\")\n\n# Load Polaris dataset\n# Note: It's easier to load the image than the ImageCollection.\n# Check the 'id' of each feature in the ImageCollection to get the link for the Image\n# Code for ImageCollection: ee.ImageCollection('projects/sat-io/open-datasets/polaris/sand_mean')\npolaris_sand = ee.Image('projects/sat-io/open-datasets/polaris/sand_mean/sand_0_5')\npolaris_clay = ee.Image('projects/sat-io/open-datasets/polaris/clay_mean/clay_0_5')\n\nBefore requesting data using the loaded GEE products, it is necessary to understand the nature of these datasets:\n\nSoil Grids\nThis dataset has a 250-meter spatial resolution (Poggio et al., 2021) and returns an image, where each band represents a depth for the given variable. After sampling the image, GEE returns a FeatureCollection with a single feature (we the .first() function to access this information). Run this line of code to inspect the output:\nsoilgrids_sand.getInfo()\n\n\nPolaris\nThis dataset has a spatial resolution of 30-meters (Chaney et al., 2019). The way we are calling this dataset it returns an Image, where each band represents a depth for a given variable. Again, after sampling the image, GEE returns a FeatureCollection with a single feature (we the .first() function to access this information).Run this line of code to inspect the output:\npolaris_clay.getInfo()\nDifferent teams aggregate data using different structures, so before using these or any other products available in GEE is important to read the documentation and inspect the data with a few examples."
  },
  {
    "objectID": "notebooks/value_at_multiple_points.html#station-data",
    "href": "notebooks/value_at_multiple_points.html#station-data",
    "title": "4  Value for multiple points",
    "section": "Station data",
    "text": "Station data\n\n# Create dictionary with station metadata\n\nstations = [\n    {'name': 'Ashland Bottoms', 'latitude': 39.125773, 'longitude': -96.63653},\n    {'name': 'Belleville 2W', 'latitude': 39.81409, 'longitude': -97.675093},\n    {'name': 'Colby', 'latitude': 39.39247, 'longitude': -101.06864},\n    {'name': 'Garden City', 'latitude': 37.99733, 'longitude': -100.81514},\n    {'name': 'Gypsum', 'latitude': 38.72522, 'longitude': -97.44415},\n    {'name': 'Hutchinson 10SW', 'latitude': 37.93097, 'longitude': -98.02},\n    {'name': 'Manhattan', 'latitude': 39.20857, 'longitude': -96.59169},\n    {'name': 'Ottawa 2SE', 'latitude': 38.54268, 'longitude': -95.24647},\n    {'name': 'Parsons', 'latitude': 37.36875, 'longitude': -95.28771},\n    {'name': 'Rossville 2SE', 'latitude': 39.11661, 'longitude': -95.91572},\n    {'name': 'Silver Lake 4E', 'latitude': 39.09213, 'longitude': -95.78153},\n    {'name': 'Tribune 6NE', 'latitude': 38.53041, 'longitude': -101.66434},\n    {'name': 'Woodson', 'latitude': 37.8612, 'longitude': -95.7836}\n]"
  },
  {
    "objectID": "notebooks/value_at_multiple_points.html#request-soil-data-for-each-station",
    "href": "notebooks/value_at_multiple_points.html#request-soil-data-for-each-station",
    "title": "4  Value for multiple points",
    "section": "Request soil data for each station",
    "text": "Request soil data for each station\n\n# We will retrieve both datasets at 250-meter resolution to match the \n# coarser dataset.\n\n# Iterate over each station metadata\nfor k,station in enumerate(stations):\n    \n    # Display current state of the loop\n    print(f\"Requesting data for {station['name']}\")\n    \n    # Convert geographic coordinates into a Point geometry\n    # following the x,y notation\n    point = ee.Geometry.Point([station['longitude'], station['latitude']])\n    \n    # Soil Grids: Sample image and then select first and only feature with property value\n    stations[k]['sand_soilgrids'] = soilgrids_sand.sample(point, 250).first().getNumber('sand_0-5cm_mean').multiply(0.1).getInfo()\n    stations[k]['clay_soilgrids'] = soilgrids_clay.sample(point, 250).first().getNumber('clay_0-5cm_mean').multiply(0.1).getInfo()\n\n    # Polaris: Sample image and then select first and only feature with property value\n    stations[k]['sand_polaris'] = polaris_sand.sample(point, 250).first().getNumber('b1').getInfo()\n    stations[k]['clay_polaris'] = polaris_clay.sample(point, 250).first().getNumber('b1').getInfo()\n    \n    \n\nRequesting data for Ashland Bottoms\nRequesting data for Belleville 2W\nRequesting data for Colby\nRequesting data for Garden City\nRequesting data for Gypsum\nRequesting data for Hutchinson 10SW\nRequesting data for Manhattan\nRequesting data for Ottawa 2SE\nRequesting data for Parsons\nRequesting data for Rossville 2SE\nRequesting data for Silver Lake 4E\nRequesting data for Tribune 6NE\nRequesting data for Woodson"
  },
  {
    "objectID": "notebooks/value_at_multiple_points.html#create-dataframe",
    "href": "notebooks/value_at_multiple_points.html#create-dataframe",
    "title": "4  Value for multiple points",
    "section": "Create DataFrame",
    "text": "Create DataFrame\n\n# Convert dictionary into a dataframe for easier visualization\ndf = pd.DataFrame(stations)\ndf.head(3)\n\n\n\n\n\n\n\n\nname\nlatitude\nlongitude\nsand\nclay\nsand_soilgrids\nclay_soilgrids\nsand_polaris\nclay_polaris\n\n\n\n\n0\nAshland Bottoms\n39.125773\n-96.636530\n15.4\n29.2\n15.4\n29.2\n3.831753\n32.519817\n\n\n1\nBelleville 2W\n39.814090\n-97.675093\n9.9\n35.6\n9.9\n35.6\n7.110556\n24.645983\n\n\n2\nColby\n39.392470\n-101.068640\n17.1\n33.2\n17.1\n33.2\n25.102043\n19.496693"
  },
  {
    "objectID": "notebooks/value_at_multiple_points.html#create-figure",
    "href": "notebooks/value_at_multiple_points.html#create-figure",
    "title": "4  Value for multiple points",
    "section": "Create Figure",
    "text": "Create Figure\nNow that we have the data from both datasets, let compare them\n\nplt.figure(figsize=(8,3))\n\nplt.subplot(1,2,1)\nplt.title('Sand 0-5 cm')\nplt.scatter(df['sand_soilgrids'], df['sand_polaris'],facecolor='w',edgecolor='k')\nplt.xlabel('Sand Soil Grids (%)')\nplt.ylabel('Sand Polaris (%)')\nplt.xlim([0,100])\nplt.ylim([0,100])\nplt.axline((0,0), slope=1, color='grey', linestyle=':')\n\nplt.subplot(1,2,2)\nplt.title('Clay 0-5 cm')\nplt.scatter(df['clay_soilgrids'], df['clay_polaris'],facecolor='w',edgecolor='k')\nplt.xlabel('Clay Soil Grids (%)')\nplt.ylabel('Clay Polaris (%)')\nplt.xlim([0,50])\nplt.ylim([0,50])\nplt.axline((0,0), slope=1, color='grey', linestyle=':')\n\nplt.subplots_adjust(wspace=0.4)\nplt.show()"
  },
  {
    "objectID": "notebooks/value_at_multiple_points.html#references",
    "href": "notebooks/value_at_multiple_points.html#references",
    "title": "4  Value for multiple points",
    "section": "References",
    "text": "References\n\nPoggio, L., De Sousa, L. M., Batjes, N. H., Heuvelink, G. B., Kempen, B., Ribeiro, E., & Rossiter, D. (2021). SoilGrids 2.0: producing soil information for the globe with quantified spatial uncertainty. Soil, 7(1), 217-240.\nParker, N., Kluitenberg, G. J., Redmond, C., & Patrignani, A. (2022). A database of soil physical properties for the Kansas Mesonet. Soil Science Society of America Journal, 86(6), 1495-1508. https://doi.org/10.1002/saj2.20465\nPatrignani, A., Knapp, M., Redmond, C., & Santos, E. (2020). Technical overview of the Kansas Mesonet. Journal of Atmospheric and Oceanic Technology, 37(12), 2167-2183. https://doi.org/10.1175/JTECH-D-19-0214.1\nChaney, N. W., Minasny, B., Herman, J. D., Nauman, T. W., Brungard, C. W., Morgan, C. L., … & Yimam, Y. (2019). POLARIS soil properties: 30‐m probabilistic maps of soil properties over the contiguous United States. Water Resources Research, 55(4), 2916-2938."
  },
  {
    "objectID": "notebooks/time_series_at_a_point.html#example-1-tallgrass-prairie-vegetation-index",
    "href": "notebooks/time_series_at_a_point.html#example-1-tallgrass-prairie-vegetation-index",
    "title": "5  Time series at a point",
    "section": "Example 1: Tallgrass prairie vegetation index",
    "text": "Example 1: Tallgrass prairie vegetation index\nRetrive and plot the enhanced vegetation index (EVI) for a point under grassland vegetation at the Konza Prairie\nProduct: MODIS\n\n# Get collection for Modis 16-day\nMCD43A4 = ee.ImageCollection('MODIS/MCD43A4_006_EVI').filterDate('2021-01-01','2021-12-31')\nEVI = MCD43A4.select('EVI')\n\n\n# Run this line to explore dataset details (output is long!)\npprint(EVI.getInfo())\n\n\n# Define point of interest\nkonza_point = ee.Geometry.Point([-96.556316, 39.084535])\n\n\n# Get data for region\nkonza_evi = EVI.getRegion(konza_point, scale=1).getInfo()\n\n\n# Run this line to inspect retrieved data (output is long!)\npprint(konza_evi)\n\n\n# Convert array into dataframe\ndf_konza = array_to_df(konza_evi)\n\n# Save dataframe as a .CSV file\n# df.to_csv('modis_evi.csv', index=False)\n\n\n# Create figure to visualize time series\nplt.figure(figsize=(6,4))\nplt.title('EVI Konza 2021')\nplt.plot(df_konza['time'], df_konza['EVI'], linestyle='-', \n         linewidth=1, marker='o', color='green')\nplt.xlabel('Date')\nplt.ylabel('EVI')\n#plt.savefig('evi_figure.png', dpi=300)\nplt.show()"
  },
  {
    "objectID": "notebooks/time_series_at_a_point.html#example-2-drought-index",
    "href": "notebooks/time_series_at_a_point.html#example-2-drought-index",
    "title": "5  Time series at a point",
    "section": "Example 2: Drought index",
    "text": "Example 2: Drought index\nDrought can be represented by a variety of indices, including soil moisture, potential atmopsheric demand, days without measurable precipitation, and indices that combine one or more of these variables. The Evaporative Demand Drought Index (EDDI) is inteded to represent the potential for drought (rather than the actual occurrence of drought).\nIn this exercise we will compare drought conditions for eastern and western Kansas during 2021 and 2022.\nProduct: GRIDMET DROUGHT\n\n# Define locations\neastern_ks = ee.Geometry.Point([-95.317201, 38.588548]) # Near Ottawa, KS\nwestern_ks = ee.Geometry.Point([-101.721117, 38.517258]) # Near Tribune, KS\n\n\n# Load EDDI product\ngridmet_drought = ee.ImageCollection(\"GRIDMET/DROUGHT\").filterDate('2021-01-01','2022-12-31')\neddi = gridmet_drought.select('eddi14d')\n\n\n# Get eddie for points\neastern_eddi = eddi.getRegion(eastern_ks, scale=1).getInfo()\nwestern_eddi = eddi.getRegion(western_ks, scale=1).getInfo()\n\n\n# Explore output\neastern_eddi[0:3]\n\n[['id', 'longitude', 'latitude', 'time', 'eddi14d'],\n ['20210105',\n  -95.31720298383848,\n  38.588547875926515,\n  1609826400000,\n  -0.029999999329447746],\n ['20210110',\n  -95.31720298383848,\n  38.588547875926515,\n  1610258400000,\n  -1.0099999904632568]]\n\n\n\n# Create dataframe for each point\ndf_eastern = array_to_df(eastern_eddi)\ndf_western = array_to_df(western_eddi)\n\n# Display a few rows\ndf_eastern.head()\n\n# Save data to a comma-separated value file\n# df.to_csv('eddi_14_day.csv', index=False)\n\n\n\n\n\n\n\n\nid\nlongitude\nlatitude\ntime\neddi14d\n\n\n\n\n0\n20210105\n-95.317203\n38.588548\n2021-01-05 06:00:00\n-0.03\n\n\n1\n20210110\n-95.317203\n38.588548\n2021-01-10 06:00:00\n-1.01\n\n\n2\n20210115\n-95.317203\n38.588548\n2021-01-15 06:00:00\n-0.03\n\n\n3\n20210120\n-95.317203\n38.588548\n2021-01-20 06:00:00\n0.39\n\n\n4\n20210125\n-95.317203\n38.588548\n2021-01-25 06:00:00\n0.39\n\n\n\n\n\n\n\n\n# Create figure to compare EDDI for both points\nplt.figure(figsize=(6,4))\nplt.title('EDDI Kansas 2021-2022')\nplt.plot(df_eastern['time'], df_eastern['eddi14d'], linestyle='-', color='navy', label='Eastern KS')\nplt.plot(df_western['time'], df_western['eddi14d'], linestyle='-', color='tomato', label='Western KS')\nplt.legend()\nplt.ylabel('14-day EDDI', size=14)\nplt.show()\n\n\n\n\n\n# Compute difference. If negative, that means that drought potential is greater in\n# western Kansas\n\nplt.figure(figsize=(6,4))\nplt.title('EDDI Difference eastern-western Kansas')\nplt.plot(df_eastern['time'], df_eastern['eddi14d']-df_western['eddi14d'], linestyle='-', color='navy')\nplt.axhline(0, linestyle='--', color='k')\nplt.ylabel('14-day EDDI', size=14)\nplt.show()"
  },
  {
    "objectID": "notebooks/time_series_at_a_point.html#example-3-irrigated-vs-rainfed-corn-vegetation-index",
    "href": "notebooks/time_series_at_a_point.html#example-3-irrigated-vs-rainfed-corn-vegetation-index",
    "title": "5  Time series at a point",
    "section": "Example 3: Irrigated vs rainfed corn vegetation index",
    "text": "Example 3: Irrigated vs rainfed corn vegetation index\n\n# Define points\ndata = {'latitude': [38.7640, 38.7628, 38.7787, 38.7642, 38.7162, 38.7783],\n        'longitude':[-101.8946, -101.8069, -101.6937, -101.9922, -101.8284, -101.9919],\n        'irrigated':[True, True, True, False, False, False]}\n\ndf = pd.DataFrame(data)\ndf.head()\n\n\n\n\n\n\n\n\nlatitude\nlongitude\nirrigated\n\n\n\n\n0\n38.7640\n-101.8946\nTrue\n\n\n1\n38.7628\n-101.8069\nTrue\n\n\n2\n38.7787\n-101.6937\nTrue\n\n\n3\n38.7642\n-101.9922\nFalse\n\n\n4\n38.7162\n-101.8284\nFalse\n\n\n\n\n\n\n\n\n# Get product\nMOD13Q1 = ee.ImageCollection(\"MODIS/061/MOD13Q1\").filterDate(ee.Date(\"2022-04-01\"),ee.Date(\"2022-11-15\"))\n\nSince in this particular exercise we have multiple locations, one simple solution is to iterate over each point and request the time series of NDVI.\n\n# Iterate over each point and retrieve NDVI\nndvi={}\n\nfor k, row in df.iterrows():\n    point = ee.Geometry.Point(row['longitude'], row['latitude'])\n    result = MOD13Q1.select('NDVI').getRegion(point, 0.01).getInfo()\n    result_in_colums = np.transpose(result)\n    ndvi[f\"field_{k+1}\"] = result_in_colums[4][1:]\n    dates = result_in_colums[0][1:]\n    \n\n\n# Create Dataframe with the NDVI data for each field\ndf_ndvi = pd.DataFrame(ndvi,dtype=float)\n\n# Add dates as index\ndf_ndvi.index = pd.to_datetime(dates, format='%Y_%m_%d')\n\n# Apply conversion factor\ndf_ndvi = df_ndvi*0.0001\n\ndf_ndvi.head()\n\n\n\n\n\n\n\n\nfield_1\nfield_2\nfield_3\nfield_4\nfield_5\nfield_6\n\n\n\n\n2022-04-07\n0.1933\n0.2024\n0.2222\n0.2934\n0.2032\n0.2007\n\n\n2022-04-23\n0.2118\n0.2178\n0.1972\n0.2785\n0.2104\n0.2107\n\n\n2022-05-09\n0.1824\n0.2039\n0.2220\n0.2328\n0.1959\n0.1827\n\n\n2022-05-25\n0.2440\n0.2056\n0.2632\n0.2115\n0.1943\n0.1902\n\n\n2022-06-10\n0.3325\n0.2236\n0.2235\n0.2186\n0.2033\n0.2054\n\n\n\n\n\n\n\n\ndf_ndvi.plot(figsize=(6,4))\nplt.title('NDVI Irrigated vs Rainfed Corn in Kansas')\nplt.xlabel('Date')\nplt.ylabel('NDVI')\nplt.show()"
  },
  {
    "objectID": "notebooks/time_series_at_a_point.html#example-4-interactive-selection",
    "href": "notebooks/time_series_at_a_point.html#example-4-interactive-selection",
    "title": "5  Time series at a point",
    "section": "Example 4: Interactive selection",
    "text": "Example 4: Interactive selection\nIn this example we will leverage the interactive functionality of the Folium library and the computer’s clipboard to get geographic coordinates with a mouse click and then retrieve time series of a vegetation index using GEE.\n\n# Define function to create raster map\n# Declare a function (blueprint)\ndef create_raster(ee_object, vis_params, name):\n    \"\"\"Function that creates a folium raster layer\"\"\"\n    raster = folium.raster_layers.TileLayer(ee_object.getMapId(vis_params)['tile_fetcher'].url_format,\n                                       name=name,\n                                       overlay=True,\n                                       control=True,\n                                       attr='Map Data &copy; &lt;a href=\"https://earthengine.google.com/\"&gt;Google Earth Engine&lt;/a&gt;')\n    return raster\n\n\n# US Counties dataset\nUS_counties = ee.FeatureCollection(\"TIGER/2018/Counties\") \n\n# Select county of interest\nstate_FIP = '20'\ncounty_name = 'Thomas'\ncounty = US_counties.filter(ee.Filter.eq('STATEFP','20').And(ee.Filter.eq('NAME','Thomas')).And(ee.Filter.eq('GEOID','20193')))\ncounty_meta = county.getInfo()\n\n\n### Select cropland datalayer ###\nstart_date = '2018-01-01'\nend_date = '2018-12-31'\nCDL = ee.ImageCollection('USDA/NASS/CDL').filter(ee.Filter.date(start_date,end_date)).first()\ncropland = CDL.select('cropland')\n\n# Clip cropland layer to selected county\ncounty_cropland = cropland.clip(county)\n\n\n### Select vegetation index (vi) ###\nband = 'EVI' # or 'NDVI'\n\n# Define start and end of time series for vegetation index\nstart_date_vi = '2017-10-15'\nend_date_vi = '2018-06-15'\n\n# Request dataset and band\nMCD43A4 = ee.ImageCollection('MODIS/MCD43A4_006_EVI').filterDate(start_date_vi,end_date_vi)\nvi = MCD43A4.select('EVI')\n\n\n# Get county boundaries\nlocation_lat = float(county_meta['features'][0]['properties']['INTPTLAT'])\nlocation_lon = float(county_meta['features'][0]['properties']['INTPTLON'])\n\n# Visualize county boundaries\nm = folium.Map(location=[location_lat, location_lon], zoom_start=10)\n\n# Add click event to paste coordinates into the clipboard\nm.add_child(folium.ClickForLatLng(alert=False))\nm.add_child(folium.LatLngPopup())\n\n# Create raster using function defined earlier and add map\ncreate_raster(county_cropland, {}, 'cropland').add_to(m)\nfolium.GeoJson(county.getInfo(),\n               name='County boundary',\n        style_function=lambda feature: {\n        'fillColor': 'None',\n        'color': 'black',\n        'weight': 2,\n        'dashArray': '5, 5'\n    }).add_to(m)\n\n# Add some controls\nfolium.LayerControl().add_to(m)\n\n# Display map\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nlat, lon = eval(clipboard.paste())\nprint(lat, lon)\n\n# Define selected coordinates as point geometry\nfield_point = ee.Geometry.Point([lon, lat])\n\npoint_evi = EVI.getRegion(field_point, scale=1).getInfo()\ndf_point = array_to_df(point_evi)\n\nif 'df' not in locals():\n    df = df_point\nelse:\n    df = pd.concat([df, df_point])\n    \nevi_mean = df.groupby(by='time', as_index=False)['EVI'].median()\nevi_mean['smoothed'] = evi_mean['EVI'].rolling(window=15, min_periods=1, center=True).mean()\n\n# Create figure\nplt.figure(figsize=(8,4))\nplt.plot(evi_mean['time'], evi_mean['smoothed'], color='tomato', linewidth=2)\nfor lat in df['latitude'].unique():\n    idx = df['latitude'] == lat\n    plt.plot(df.loc[idx,'time'], df.loc[idx,'EVI'], linestyle='-', linewidth=1, color='gray')\n\nplt.show()\n\n39.402244 -100.990448"
  },
  {
    "objectID": "notebooks/static_image_for_an_area.html#define-helper-functions",
    "href": "notebooks/static_image_for_an_area.html#define-helper-functions",
    "title": "6  Image for an area",
    "section": "Define helper functions",
    "text": "Define helper functions\n\n# Define function to save images to the local drive \ndef save_geotiff(ee_image, filename, crs, scale, geom, bands=[]):\n    \"\"\"\n    Function to save images from Google Earth Engine into local hard drive.\n    \"\"\"\n    image_url = ee_image.getDownloadUrl({'region': geom,'scale':scale, \n                                         'bands': bands,\n                                         'crs': f'EPSG:{crs}', \n                                         'format': 'GEO_TIFF'})\n    \n    # Request data using URL and save data as a new GeoTiff file\n    response = requests.get(image_url)\n    with open(filename, 'wb') as f:\n        f.write(response.content)\n        return print('Saved image')\n    \n    \n# Define function to retrieve colormaps\ndef get_hex_cmap(name,n=10):\n    \"\"\"\n    Function to get list of HEX colors from a Matplotlib colormap.\n    \"\"\"\n    rgb_cmap = colormaps.get_cmap(name)\n    rgb_index = np.linspace(0, rgb_cmap.N-1, n).astype(int)\n    hex_cmap = [colors.rgb2hex(rgb_cmap(k)) for k in rgb_index]\n    return hex_cmap"
  },
  {
    "objectID": "notebooks/static_image_for_an_area.html#example-1-state-level-elevation",
    "href": "notebooks/static_image_for_an_area.html#example-1-state-level-elevation",
    "title": "6  Image for an area",
    "section": "Example 1: State level elevation",
    "text": "Example 1: State level elevation\n\n# Read US states\nUS_states = ee.FeatureCollection(\"TIGER/2018/States\")\n\n# Select Kansas\nregion = US_states.filter(ee.Filter.eq('NAME','Kansas'))\n\n# Create mask\nmask = ee.Image.constant(1).clip(region).mask()\n\n\n# Get image with elevation data from the Shuttle Radar Topography Mission (SRTM)\nsrtm = ee.Image(\"USGS/SRTMGL1_003\")\nelev_img = srtm.clip(region).mask(mask)\n\n\n# Get colormap for both geotiff raster and folium raster amp \ncmap = get_hex_cmap('Spectral', 12)\n\n\n# Save geotiff\nelev_filename = '../outputs/kansas_elevation_250m.tif'\nsave_geotiff(elev_img, elev_filename, crs=4326, scale=250, geom=region.geometry())\n\nSaved image\n\n\n\n# Read GeoTiff file using Xarray (and remove extra dimension)\nelev_raster = xr.open_dataarray(elev_filename).squeeze()\n\n\n# Create figure\nelev_raster.plot.imshow(figsize=(6,3), cmap='Spectral', add_colorbar=True,\n                   cbar_kwargs={'label':'Elevation m'});\nplt.title('Kansas Elevation Map')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\n#plt.axis('equal')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/static_image_for_an_area.html#example-2-state-level-soil-textural-class",
    "href": "notebooks/static_image_for_an_area.html#example-2-state-level-soil-textural-class",
    "title": "6  Image for an area",
    "section": "Example 2: State level soil textural class",
    "text": "Example 2: State level soil textural class\nIn this example we will plot the 12 soil textural classes for the state of Kansas. We will also learn how to use Matplotlib’s object-based syntax to define a colorbar with custom labels. The source for this example is from the 800-meter spatial resolution gridded soil product created by Walkinshaw et al. (2020) using the USDA-NRCS Soil Survey Geodatabase. Check out the link below for some cool maps:\n\nWalkinshaw, Mike, A.T. O’Geen, D.E. Beaudette. “Soil Properties.” California Soil Resource Lab, 1 Oct. 2020, casoilresource.lawr.ucdavis.edu/soil-properties/.\n\n\n# Read US states\nUS_states = ee.FeatureCollection(\"TIGER/2018/States\")\n\n# Select Kansas\nregion = US_states.filter(ee.Filter.eq('NAME','Kansas'))\n\n# Create mask\nmask = ee.Image.constant(1).clip(region).mask()\n\n\nurl_link = 'projects/earthengine-legacy/assets/projects/sat-io/open-datasets/CSRL_soil_properties/physical/soil_texture_profile/texture_025'\ntexture_img = ee.Image(url_link).clip(region).mask(mask)\n\n# Palette\npalette = ['#BEBEBE', #Sand\n           '#FDFD9E', #Loamy Sand\n           '#ebd834', #Sandy Loam\n           '#307431', #Loam\n           '#CD94EA', #Silt Loam\n           '#546BC3', #Silt\n           '#92C158', #Sandy Clay Loam\n           '#EA6996', #Clay Loam\n           '#6D94E5', #Silty Clay Loam\n           '#4C5323', #Sandy Clay\n           '#E93F4A', #Silty Clay\n           '#AF4732', #Clay\n          ]\n\n# Visualization parameters\ntexture_cmap = colors.ListedColormap(palette)\n\n# Save geotiff\ntexture_filename = '../outputs/kansas_texture_800m.tif'\nsave_geotiff(texture_img, texture_filename, crs=4326, scale=800, geom=region.geometry())\n\nSaved image\n\n\n\n# Read saved geotiff image\ntexture_raster = xr.open_dataarray(texture_filename).squeeze()\n\n\nfig, ax = plt.subplots(figsize=(6,3))\n\nraster = texture_raster.plot.imshow(ax=ax, cmap=texture_cmap, \n                                    add_colorbar=False, vmin=1, vmax=13)\n\nax.set_title('Textural Class 0-25 cm')\nax.set_xlabel('Latitude', fontsize=12)\nax.set_xlabel('Longitude', fontsize=12)\nax.grid(which='major', color='lightgrey', linestyle=':')\n\n# Add colorbar\ncbar = fig.colorbar(raster, ax=ax)\n\n# Customize the colorbar\ncbar.set_ticks(ticks=np.linspace(1.5, 12.5, 12),\n               labels=['Sand','Loamy sand','Sandy loam',\n                       'Loam','Silt loam','Silt',\n                       'Sandy clay loam','Clay loam',\n                       'Silty clay loam','Sandy clay',\n                       'Silty clay','Clay'])\n\nplt.tight_layout()\n#plt.savefig('flint_hills.jpg', dpi=300)\nplt.show()"
  },
  {
    "objectID": "notebooks/static_image_for_an_area.html#example-3-regional-soil-properties",
    "href": "notebooks/static_image_for_an_area.html#example-3-regional-soil-properties",
    "title": "6  Image for an area",
    "section": "Example 3: Regional soil properties",
    "text": "Example 3: Regional soil properties\n\n# Ecoregions map\n# https://developers.google.com/earth-engine/datasets/catalog/RESOLVE_ECOREGIONS_2017#description\neco_regions = ee.FeatureCollection(\"RESOLVE/ECOREGIONS/2017\")\n\n# Select flint hills region\nregion = eco_regions.filter(ee.Filter.inList('ECO_ID',[392])) # Find ecoregion ID using their website: https://ecoregions.appspot.com\n\n# Define approximate region bounding box [E,S,W,N]\nbbox = ee.Geometry.Rectangle([-95.6, 36, -97.4, 40])\n\n# Create mask for the region\nmask = ee.Image.constant(1).clip(region).mask()\n\n\nLoad maps of soil physical properties\n\n# SAND\n\n# Select layer, clip to region, and then mask\nsand = ee.Image(\"projects/soilgrids-isric/sand_mean\").clip(region).mask(mask)\nsand_img = sand.select('sand_0-5cm_mean').multiply(0.1) # From g/kg to %\n\n\n# Save geotiff\nsand_filename = '../outputs/flint_hills_sand_800m.tif'\nsave_geotiff(sand_img, sand_filename, crs=4326, scale=250, geom=region.geometry())\n\nSaved image\n\n\n\n# SOIL ORGANIC CARBON\n\n# Select layer, clip to region, and then mask\nsoc = ee.Image(\"projects/soilgrids-isric/soc_mean\").clip(region).mask(mask)\n\n# Select surface sand layer\nsoc_img = soc.select('soc_0-5cm_mean').multiply(0.01) # From dg/kg to %\n\n\n# Save geotiff\nsoc_filename = '../outputs/flint_hills_soc_800m.tif'\nsave_geotiff(soc_img, soc_filename, crs=4326, scale=250, geom=region.geometry())\n\nSaved image\n\n\n\n# Read GeoTiff images saved in our local drive\nsand_raster = xr.open_dataarray(sand_filename).squeeze()\nsoc_raster = xr.open_dataarray(soc_filename).squeeze()\n\n\n# Create figure\nfs = 12 # Define font size variable\n\nplt.figure(figsize=(6,4))\n\nplt.subplot(1,2,1)\nsand_raster.plot.imshow(cmap='OrRd', add_colorbar=True, vmin=0, vmax=50,\n                   cbar_kwargs={'label':'Sand (%)', 'shrink':0.5});\nplt.title('Sand 0-25 cm')\nplt.xlabel('Longitude', fontsize=fs)\nplt.ylabel('Latitude', fontsize=fs)\nplt.xticks(fontsize=fs)\nplt.yticks(fontsize=fs)\nplt.grid(which='major', color='lightgrey', linestyle=':')\nplt.arrow(-95.75, 36.5, 0, 0.2, head_width=0.1, head_length=0.1, fc='k', ec='k')\nplt.text(-95.75, 36.25, 'N', fontsize=15, ha='center')\nplt.xlim([-97.5, -95.5])\nplt.ylim([36, 40])\n\n\nplt.subplot(1,2,2)\nsoc_raster.plot.imshow(cmap='copper_r', add_colorbar=True, vmin=0, vmax=6,\n                   cbar_kwargs={'label':'SOC (%)', 'shrink':0.5});\nplt.title('Organic carbon 0-25 cm')\nplt.xlabel('Longitude', fontsize=fs)\nplt.ylabel('Latitude', fontsize=fs)\nplt.xticks(fontsize=fs)\nplt.yticks(fontsize=fs)\nplt.grid(which='major', color='lightgrey', linestyle=':')\nplt.xlim([-97.5, -95.5])\nplt.ylim([36,40])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/static_image_for_an_area.html#example-4-regional-drought",
    "href": "notebooks/static_image_for_an_area.html#example-4-regional-drought",
    "title": "6  Image for an area",
    "section": "Example 4: Regional drought",
    "text": "Example 4: Regional drought\nIn this example we will explore how to retrieve available dates for an Image Collection and then we will use that information to select a specific Image. More specifically, to illsutrate these concepts we will use the collection from the U.S. Drought Monitor, that releases weekly maps of drought conditions for the United States. The selected region for the map is the area covering the Ogallala aquifer, which is one of the largest aquifers in the world spanning multiple states in the U.S. Great Plains.\n\nRead boundary\n\n# Import boundary for Ogallala Aquifer from local drive\nfilename_bnd = '../datasets/ogallala_aquifer_bnd.geojson'\n\n# Read the file\nwith open(filename_bnd) as file:\n    roi_json = json.load(file)\n\n# Get coordinates for plot\nlon,lat = zip(*roi_json['features'][0]['geometry']['coordinates'][0])\n\n# Define the ee.Geometry so that GEE can use it\nroi_geom = ee.Geometry(roi_json['features'][0]['geometry'])\n\n# Create mask\nmask = ee.Image.constant(1).clip(roi_geom).mask()\n\n\n\nLoad USDM image collection\n\n# Load U.S. Drought monitor Image Collection\nusdm_collection = ee.ImageCollection(\"projects/sat-io/open-datasets/us-drought-monitor\")\n\nTo access a specific number of items from a collection, we can use the .toList() method. For instance, to return the first three images of the U.S. Drought Monitor collection defined above we can run the following command: usdm_collection.toList(3).getInfo()\n\n# Define function to get dates from each ee.Image object\nget_date = lambda image: ee.Image(image).date().format('YYYY-MM-dd')\n\n# Get the size of the image collection\nN = usdm_collection.size()\n\n\n# Apply function to collection\nusdm_dates = usdm_collection.toList(N).map(get_date).getInfo()\n\n# Iterate over all the dates and select images for August 2011\nfor k,date in enumerate(usdm_dates):\n    date = datetime.strptime(date, '%Y-%m-%d')\n    if date.year == 2012 and date.month == 10:\n        print(k, date)\n\n666 2012-10-02 00:00:00\n667 2012-10-09 00:00:00\n668 2012-10-16 00:00:00\n669 2012-10-23 00:00:00\n670 2012-10-30 00:00:00\n\n\nNote that the following code will not work:\nget_date = lambda image: image.date().format('YYYY-MM-dd')\nusdm_dates = usdm_collection.map(get_date).getInfo()\nThe reason it does not work is because a mapping algorithm on a collection must return a Feature or Image, and the above code returns a date string.\n\n# Read specific image\nimage_number = 670\nusdm_img = ee.Image(usdm_collection.toList(N).get(image_number))\n\n# Clip and add 1 to the layer, so that we represent \"None\" as 0\nusdm_img = usdm_img.clip(roi_geom).add(1).mask(mask)\n\n# Get latest image of collection\n# usdm_img = ee.Image(usdm_collection.toList(N).get(-1)).mask(mask)\n\n# Get first image of collection\n# usdm_img = ee.Image(usdm_collection.toList(N).get(0)).mask(mask) # or\n# usdm_img = ee.Image(usdm_collection.toList(1)).mask(mask)\n\n\n# Define colormap\nusdm_hex_palette = [\"#FFFFFF\", \"#FFFF00\", \"#FCD37F\", \"#FFAA00\", \"#E60000\", \"#730000\"]\n\n# Visualization parameters\nusdm_cmap = colors.ListedColormap(usdm_hex_palette)\nusdm_cmap\n\nfrom_list  underbad over \n\n\n\n# Get map from url (it may take several seconds)\nimage_url = usdm_img.getDownloadUrl({\n    'region': roi_geom,\n    'scale':1_000,\n    'crs': 'EPSG:4326',\n    'format': 'GEO_TIFF'})\n\n# Request data using URL and save data as a new GeoTiff file\nresponse = requests.get(image_url)\n   \n\n\n# Check if the request was successful\nif response.status_code == 200:\n    \n    # Read image data into a BytesIO object\n    image_data = io.BytesIO(response.content)\n    \n    fig,ax = plt.subplots(figsize=(4,6))\n    \n    # Use Xarray to open the raster image directly from memory\n    raster = xr.open_dataarray(image_data, engine='rasterio').squeeze()\n    \n    # Create raster map showing drought conditions\n    usdm_map = raster.plot.imshow(ax=ax, cmap=usdm_cmap, \n                                  vmin=-0.5, vmax=5.5, add_colorbar=False)\n    \n    # Add aquifer boundaries\n    ax.plot(lon, lat, color='k', linewidth=1)\n    \n    # Add colorbar\n    cbar = fig.colorbar(usdm_map, ax=ax, shrink=0.5, label='Drought Intensity')\n\n    # Add labels in the center of each segment\n    cbar.set_ticks(ticks=[0,1,2,3,4,5],\n                   labels=['None','D0','D1','D2','D3','D4'])\n\n    # Add labels\n    ax.set_title(f'Ogallala Aquifer {usdm_dates[image_number]}')\n    ax.set_xlabel('Longitude')\n    ax.set_ylabel('Latitude')\n    plt.grid(linestyle=':')\n    plt.show()"
  },
  {
    "objectID": "notebooks/reduce_image_collection_to_image.html#define-helper-functions",
    "href": "notebooks/reduce_image_collection_to_image.html#define-helper-functions",
    "title": "7  Reduce collection to image",
    "section": "Define helper functions",
    "text": "Define helper functions\n\n# Define function to save images to the local drive \ndef save_geotiff(ee_image, filename, crs, scale, geom, bands=[]):\n    \"\"\"\n    Function to save images from Google Earth Engine into local hard drive.\n    \"\"\"\n    image_url = ee_image.getDownloadUrl({'region': geom,'scale':scale, \n                                         'bands': bands,\n                                         'crs': f'EPSG:{crs}', \n                                         'format': 'GEO_TIFF',\n                                         'formatOptions': {'cloudOptimized': True,\n                                                           'noDataValue': 0}})\n    \n    # Request data using URL and save data as a new GeoTiff file\n    response = requests.get(image_url)\n    with open(filename, 'wb') as f:\n        f.write(response.content)\n        return print('Saved image')"
  },
  {
    "objectID": "notebooks/reduce_image_collection_to_image.html#example-1-sum-reducers",
    "href": "notebooks/reduce_image_collection_to_image.html#example-1-sum-reducers",
    "title": "7  Reduce collection to image",
    "section": "Example 1: Sum reducers",
    "text": "Example 1: Sum reducers\nThe sum reducer adds up all the values it encounters. This is useful for calculating total rainfall, snowfall, or any other cumulative measure over an area. IN this example we will compute the annual precipitation in 2023 across Oklahoma.\n\n# Read US states\nUS_states = ee.FeatureCollection(\"TIGER/2018/States\")\n\n# Select Kansas\nregion = US_states.filter(ee.Filter.eq('NAME','Oklahoma'))\n\n# Create mask\nmask = ee.Image.constant(1).clip(region).mask()\n\n\n\n\n\n\n\nNote\n\n\n\nThe clip() method only affects the visualization of the image in Google Earth Engine. To ensure the image is clipped in the exported GeoTIFF, we need to explicitly apply the mask.\n\n\n\nprism = ee.ImageCollection('OREGONSTATE/PRISM/AN81d').filterDate('2023-01-01', '2023-12-31')\nprecip_img = prism.select('ppt').reduce(ee.Reducer.sum()).mask(mask)\n\n\n\n\n\n\n\nNote\n\n\n\nThe result of applying a reducer to an ImageCollection is an Image.\n\n\n\n# Save geotiff\nprecip_filename = '../outputs/oklahoma_rainfall_2023.tif'\nsave_geotiff(precip_img, precip_filename, crs=4326, scale=4_000, geom=region.geometry())\n\nSaved image\n\n\n\n# Read saved geotiff image\nprecip_raster = xr.open_dataarray(precip_filename).squeeze()\n\n\n# Get coordinates of the county geometry\ndf = pd.DataFrame(region.first().getInfo()['geometry']['coordinates'][0])\ndf.columns = ['lon','lat']\ndf.head()\n\n\n\n\n\n\n\n\nlon\nlat\n\n\n\n\n0\n-103.002435\n36.675527\n\n\n1\n-103.002390\n36.670994\n\n\n2\n-103.002390\n36.668480\n\n\n3\n-103.002390\n36.664934\n\n\n4\n-103.002390\n36.661792\n\n\n\n\n\n\n\n\n# Create figure\nprecip_raster.plot.imshow(figsize=(6,3), cmap='Spectral', add_colorbar=True,\n                   cbar_kwargs={'label':'Precipitation (mm)'})\nplt.plot(df['lon'], df['lat'],'-k')\nplt.title('Oklahoma Precipitation 2023')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\n#plt.axis('equal')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Create contour figure\nprecip_raster.plot.contourf(figsize=(6,3), cmap='Spectral', add_colorbar=True,\n                   cbar_kwargs={'label':'Precipitation (mm)'})\nplt.plot(df['lon'], df['lat'],'-k')\nplt.title('Oklahoma Precipitation 2023')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\n#plt.axis('equal')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Find min and max precipitation\nprecip_img.reduceRegion(reducer = ee.Reducer.minMax(),\n                        geometry = region.geometry(),\n                        scale = 4_000).getInfo()\n\n{'ppt_sum_max': 1753.4329500616004, 'ppt_sum_min': 349.43359203080763}\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe .minMax() reducer finds the minimum and maximum value. This particular reducer is useful for identifying extremes like the coldest and hottest temperatures or the lowest and highest annual precipitation amounts."
  },
  {
    "objectID": "notebooks/reduce_image_collection_to_image.html#example-2-min-reducer",
    "href": "notebooks/reduce_image_collection_to_image.html#example-2-min-reducer",
    "title": "7  Reduce collection to image",
    "section": "Example 2: Min Reducer",
    "text": "Example 2: Min Reducer\nThe .min() reducer finds the minimum value. In this example we will determine the minimum and maximum land surface teperatures.\n\n# Read US states\nUS_states = ee.FeatureCollection(\"TIGER/2018/States\")\n\n# Select Kansas\nregion = US_states.filter(ee.Filter.eq('NAME','Kansas'))\n\n# Create mask\nmask = ee.Image.constant(1).clip(region).mask()\n\n\n# Load an image collection from PRISM\nprism = ee.ImageCollection('OREGONSTATE/PRISM/AN81d').filterDate('2010-01-01', '2020-12-31').filterBounds(region)\ntmin_img = prism.select('tmin').reduce(ee.Reducer.min()).mask(mask)\n\n\n# Save geotiff\ntmin_filename = '../outputs/kansas_tmin_2010_2020.tif'\nsave_geotiff(tmin_img, tmin_filename, crs=4326, scale=4000, geom=region.geometry())\n\nSaved image\n\n\n\n# Read saved geotiff image\ntmin_raster = xr.open_dataarray(tmin_filename).squeeze()\n\n\n# Get the dictionary with all the metadata into a variable\n# Print this variable to see the details\nregion_metadata = region.first().getInfo()\n\n# Get coordinates of the county geometry\ndf = pd.DataFrame(region_metadata['geometry']['geometries'][1]['coordinates'][0])\ndf.columns = ['lon','lat']\n\n\n\n# Create figure\ntmin_raster.plot.imshow(figsize=(6,3), cmap='cool_r', add_colorbar=True,\n                   cbar_kwargs={'label':'Temperature (Celsius)'})\nplt.plot(df['lon'], df['lat'],'-k')\nplt.title('Kansas Air Temperature 2010-2020')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\n#plt.axis('equal')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Find lowest temperature\ntmin_img.reduceRegion(reducer = ee.Reducer.min(),\n                        geometry = region.geometry(),\n                        scale = 4_000).getInfo()\n\n{'tmin_min': -30.395000457763672}\n\n\n\nI still need to figure out how to obtain the coordinates of the location with the lowest temperature. If someone know the answer, please send me an e-mail or push the code to Github."
  },
  {
    "objectID": "notebooks/reduce_image_collection_to_image.html#example-4-max-reducer",
    "href": "notebooks/reduce_image_collection_to_image.html#example-4-max-reducer",
    "title": "7  Reduce collection to image",
    "section": "Example 4: Max reducer",
    "text": "Example 4: Max reducer\nThe .max() reducer find the maximum value. In this example we will use it to find the total spatial extent burned by wildfires over multiple days in southwest Kansas and northwest Oklahoma.\nThe Starbuck wildfire occurred in March 2017 and stands as one of the largest wildfires in Kansas history. The Starbuck wildfire started in Beaver county in Oklahoma and then spread across multiple Kansas counties, including Meade, Clark, and Comanche counties, ravaging over 662,000 acres of land that included ranches and residential areas. The fire’s magnitude was so extensive that it not only caused significant ecological damage but also resulted in the loss of numerous cattle, property destruction, and challenged the resilience of local communities. The Starbuck wildfire highlighted the importance of community solidarity, the challenges of managing fire risk in rural regions, and the necessity for improved fire management, preparedness, and mitigation strategies.\n\n# Load the US county boundaries.\ncounties = ee.FeatureCollection('TIGER/2016/Counties');\n\n# Filter the counties by name and state (Kansas FIPS code is \"20\")\nks_counties = counties.filter(ee.Filter.Or(ee.Filter.eq('NAME', 'Clark'),\n                                           ee.Filter.eq('NAME', 'Meade'),\n                                           ee.Filter.eq('NAME', 'Comanche'))).filter(ee.Filter.eq('STATEFP', '20')) \n\n# Filter the counties by name and state (Oklahoma FIPS code is \"40\")\nok_counties = counties.filter(ee.Filter.Or(ee.Filter.eq('NAME', 'Beaver'),\n                                           ee.Filter.eq('NAME', 'Harper'))).filter(ee.Filter.eq('STATEFP', '40')) \n\n\n## Combine the selected counties into a single geometry.\nregion = ks_counties.merge(ok_counties)\n\n# Combined counties (not use in the tutorial)\nregion_union = region.union()\n\n# Get bounding box of combined geometry\nbbox = region.geometry().bounds()\n\n\n\n\n\n\n\nNote\n\n\n\nFor combining FeatureCollections we use the merge() method. To combine geometries or features within a FeatureCollection we use the .union() method.\n\n\n\n# Load modis product\nmodis = ee.ImageCollection('MODIS/061/MOD14A1').filterDate('2017-03-01', '2017-03-31')\nmax_fire = modis.select('FireMask').reduce(ee.Reducer.max())\n\n\n# Save GeoTIFF\nmax_fire_filename = '../outputs/starbuck_wildfire_.tiff'\nsave_geotiff(max_fire, filename=max_fire_filename, crs=4326, scale=1000, \n             geom=bbox, bands=[])\n\nSaved image\n\n\n\n# Get geometry coordinates for all counties (this is a MultiPolygon object)\nregion_geom = region.geometry().getInfo()\n\n\n# Read saved geotiff image\nmax_fire_raster = xr.open_dataarray(max_fire_filename).squeeze()\n\n\n# Paletter of colors for the Enhanced Vegetation Index\nhex_palette = ['#ffffff','#ff0000']\n\n# Use the built-in ListedColormap function to do the conversion\ncmap = colors.ListedColormap(hex_palette)\n\n\n# Create figure\nmax_fire_raster.plot.imshow(figsize=(6,4), cmap=cmap, add_colorbar=False)\n\nfor r in region_geom['coordinates']:\n    lon,lat = zip(*r[0])\n    plt.plot(list(lon), list(lat), linestyle='-', linewidth=1, color='grey')\n    \nplt.title('Region with multiple large wildfires in 2017')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\n#plt.axis('equal')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/reduce_image_collection_to_image.html#example-5-median-reducer",
    "href": "notebooks/reduce_image_collection_to_image.html#example-5-median-reducer",
    "title": "7  Reduce collection to image",
    "section": "Example 5: Median reducer",
    "text": "Example 5: Median reducer\nThe median reducer computes the typicalvalue of a set of numbers. It’s often used to aggregate pixel values across images or image collections.\nIn this example we will compute the median enhanced vegetation index for a county and we learn how to:\n\nfilter a FeatureCollection,\ncompute the median of an ImageCollection,\ncreate, apply, and update a mask,\nretrieve, save, and read a geotiff image\n\n\n# US Counties dataset\nUS_counties = ee.FeatureCollection(\"TIGER/2018/Counties\") \n\n# Select county of interest\ncounty = US_counties.filter(ee.Filter.eq('GEOID','20161'))\n\n# Create mask\nmask = ee.Image.constant(1).clip(county).mask()\n\n\n# Modis EVI\nmodis_evi = ee.ImageCollection('MODIS/MCD43A4_006_EVI')\n\nevi_img = modis_evi.filterDate('2021-04-01', '2021-09-30') \\\n         .select('EVI').filterBounds(county).median()\n\n# Create mask for region\nevi_img = evi_img.mask(mask)\n\n# Update mask to avoid water bodies (wich typically have evi&lt;0.2)\nevi_img = evi_img.updateMask(evi_img.gt(0.2))\n\n\n\n\n\n\n\nNote\n\n\n\ncollection.median() is a shorter way to compute the median than collection.reduce(ee.Reducer.median()). The latter offers more flexibility and allows for additional configurations not available through the shorter and more convenient method.\n\n\n\n# Set visualization parameters.\n# https://colorbrewer2.org/#type=sequential&scheme=YlOrBr&n=7\nevi_palette = ['#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901',\n             '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01',\n             '#012E01', '#011D01', '#011301']\nevi_cmap = colors.ListedColormap(evi_palette)\n\n\n# Save geotiff image\nevi_filename = '../outputs/evi_riley_county.tif'\nsave_geotiff(evi_img, evi_filename, crs=4326, scale=250, \n             geom=county.geometry(), bands=['EVI'])\n\nSaved image\n\n\n\n# Read GeoTiff file using the Xarray package\nevi_raster = xr.open_dataarray(evi_filename).squeeze()\n\n\n# Get coordinates of the county geometry\ndf = pd.DataFrame(county.first().getInfo()['geometry']['coordinates'][0])\ndf.columns = ['lon','lat']\ndf.head()\n\n\n\n\n\n\n\n\nlon\nlat\n\n\n\n\n0\n-96.961683\n39.220095\n\n\n1\n-96.961369\n39.220095\n\n\n2\n-96.956566\n39.220005\n\n\n3\n-96.954188\n39.220005\n\n\n4\n-96.952482\n39.220005\n\n\n\n\n\n\n\n\n# Create figure\n\nplt.figure(figsize=(6,4))\nevi_raster.plot.imshow(cmap=evi_cmap, vmin=0.2, vmax=0.7, \n                       levels=10, cbar_kwargs={'label':'EVI', 'format':\"{x:.2f}\"}) # Can also pass robust=True\nplt.plot(df['lon'], df['lat'],'-k')\nplt.title('Riley county EVI - 2021', size=12)\nplt.xlabel('Longitude', size=12)\nplt.ylabel('Latitude', size=12)\nplt.xlim([-97,-96.35])\nplt.ylim([39, 39.6])\nplt.axis('equal')\n#plt.savefig('../outputs/riley_county_median_evi.jpg', dpi=300)\nplt.show()"
  },
  {
    "objectID": "notebooks/reduce_image_collection_to_image.html#example-6-mean-reducer",
    "href": "notebooks/reduce_image_collection_to_image.html#example-6-mean-reducer",
    "title": "7  Reduce collection to image",
    "section": "Example 6: Mean reducer",
    "text": "Example 6: Mean reducer\nThe mean reducer computes the pixel-wise average value of a set of images in a collection. It’s often used to aggregate pixel values across images or image collections. In this exercise we will compute the mean NDVI for each pixel over a watershed.\n\n# Read US watersheds using hydrologic unit codes (HUC)\nwatersheds = ee.FeatureCollection(\"USGS/WBD/2017/HUC12\")\nmcdowell_creek = watersheds.filter(ee.Filter.eq('huc12', '102701010204')).first()\n\n# Get geometry so that we can plot the boundary\nmcdowell_creek_geom = mcdowell_creek.geometry().getInfo()\n\n# Create mask for the map\nmask = ee.Image.constant(1).clip(mcdowell_creek).mask()\n\n\n# Get watershed boundaries\ndf_mcdowell_creek_bnd = pd.DataFrame(np.squeeze(mcdowell_creek_geom['coordinates']),\n                                     columns=['lon','lat'])\n# Inspect dataframe\ndf_mcdowell_creek_bnd.head()\n\n\n\n\n\n\n\n\nlon\nlat\n\n\n\n\n0\n-96.552986\n39.093157\n\n\n1\n-96.553307\n39.093741\n\n\n2\n-96.553592\n39.094234\n\n\n3\n-96.553683\n39.094391\n\n\n4\n-96.553988\n39.094490\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSometimes regions like watersheds are returned as a feature instead of a geometry. This will not work for reducing operations. To solve the problem we can use the geometry() method. To inspect whether the returned object is a feature or a geometry use the getInfo() method to inspect the object.\n\n\n\n# Get collection for Terra Vegetation Indices 16-Day Global 500m\nstart_date = '2022-01-01'\nend_date = '2022-12-31'\ncollection = ee.ImageCollection('MODIS/006/MOD13A1').filterDate(start_date, end_date)\n\n\n# Reduce the collection to an image with a median reducer.\nndvi_mean = collection.mean().multiply(0.0001).clip(mcdowell_creek)\n\n# Apply mask\nndvi_mean = ndvi_mean.mask(mask)\n\n# Save geotiff image\nndvi_filename = '../outputs/ndvi_mean_mcdowell_creek.tif'\nsave_geotiff(ndvi_mean, ndvi_filename, crs=4326, scale=250, \n             geom=mcdowell_creek.geometry(), bands=['NDVI'])\n\nSaved image\n\n\n\n# Define NDVI colormap\nhex_palette = ['#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901',\n             '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01',\n             '#012E01', '#011D01', '#011301']\n\n# Use the built-in ListedColormap function to do the conversion\nndvi_cmap = colors.ListedColormap(hex_palette)\n\n\n# Read GeoTiff file using the Xarray package\nraster = xr.open_dataarray(filename).squeeze()\n\nplt.figure(figsize=(6,5))\nraster.plot(cmap=ndvi_cmap, cbar_kwargs={'label':'NDVI'}, vmin=0.1, vmax=0.7)\nplt.plot(df_mcdowell_creek_bnd['lon'], df_mcdowell_creek_bnd['lat'], color='r')\nplt.title('McDowell Creek watershed')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()"
  },
  {
    "objectID": "notebooks/reduce_image_collection_to_image.html#example-7-count-reducer-over-a-region",
    "href": "notebooks/reduce_image_collection_to_image.html#example-7-count-reducer-over-a-region",
    "title": "7  Reduce collection to image",
    "section": "Example 7: Count reducer over a region",
    "text": "Example 7: Count reducer over a region\nThe count reducer tallies the number of values, useful for counting the number of observations or pixels within a region that meet certain criteria. In this example we will find the area of Kansas covered by grasslands. If you thought that Kansas was mostly covered by cropland, then you are up for a surprise.\n\n# Read US states\nUS_states = ee.FeatureCollection(\"TIGER/2018/States\")\n\n# Select Kansas\nregion = US_states.filter(ee.Filter.inList('NAME',['Kansas']))\n\n\n# Land use for 2021\nland_use = ee.ImageCollection('USDA/NASS/CDL') \\\n             .filter(ee.Filter.date('2021-01-01', '2021-12-31')).first().clip(region)\n\n# Select cropland layer\ncropland = land_use.select('cropland')\n\n\n# Select pixels for a cover\nland_cover_value = 176 # This is the code for grasslands\nland_cover_img = cropland.eq(land_cover_value).selfMask()\n\n\n# Save geotiff image\nland_cover_filename = '../outputs/land_cover_kansas.tif'\nsave_geotiff(land_cover_img, land_cover_filename, crs=4326, scale=250, \n             geom=region.geometry())\n\nSaved image\n\n\n\n# Read GeoTiff file using the Xarray package\nland_cover_raster = xr.open_dataarray(land_cover_filename).squeeze()\n\n\n# Get the dictionary with all the metadata into a variable\n# Print this variable to see the details\nregion_metadata = region.first().getInfo()\n\n# Get coordinates of the county geometry\ndf = pd.DataFrame(region_metadata['geometry']['geometries'][1]['coordinates'][0])\ndf.columns = ['lon','lat']\n\n\n# Create figure\n\nplt.figure(figsize=(6,4))\nland_cover_raster.plot.imshow(cmap='Greens', add_colorbar=False)\nplt.plot(df['lon'], df['lat'],'-k')\nplt.title('Kansas Grassland Land Cover', size=12)\nplt.xlabel('Longitude', size=12)\nplt.ylabel('Latitude', size=12)\nplt.xlim([-97,-96.35])\nplt.ylim([39, 39.6])\nplt.axis('equal')\n#plt.savefig('../outputs/kansas_grasslands.jpg', dpi=300)\nplt.show()\n\n\n\n\n\n# Reduce the collection and compute area of land cover\n# Kansas has an area of 213,100 square kilometers\n\n# Apply reducer\nland_cover_count = land_cover_img.reduceRegion(reducer=ee.Reducer.count(),\n                                               geometry=region.geometry(),\n                                               scale=250)\n\nland_cover_pixels = land_cover_count.get('cropland').getInfo()\nprint(f'There are a total of {land_cover_pixels:,} pixels under grassland at 250 m spatial resolution per pixel')\n\nstate_area = 213_000 # km^2\nstate_fraction = (land_cover_pixels*250**2) / 10**6 / state_area \nprint(f'Kansas has a {round(state_fraction*100)} % of the area covered by grassland')\n\n\nThere are a total of 1,444,936 pixels under grassland at 250 m spatial resolution per pixel\nKansas has a 42 % of the area covered by grassland\n\n\nThe reduceRegion() function applies a reducer to all the pixels in a specified region. Altrnatively you can pass options as keyword arguments using a dictionary, like so:\nland_cover_count = land_cover_img.reduceRegion(**{\n    'reducer': ee.Reducer.count(),\n    'geometry': region.geometry(),\n    'scale': 250})"
  },
  {
    "objectID": "notebooks/reduce_image_collection_to_timeseries.html#example-1-mean-vegetation-dynamics-for-entire-watershed",
    "href": "notebooks/reduce_image_collection_to_timeseries.html#example-1-mean-vegetation-dynamics-for-entire-watershed",
    "title": "8  Reduce collection to time series",
    "section": "Example 1: Mean vegetation dynamics for entire watershed",
    "text": "Example 1: Mean vegetation dynamics for entire watershed\nIn this exercise we will reduce an image collection into a time series of average values of Enhanced Vegetation Index (EVI) for the region of interest over the specified date range.\n\n# Trigger the authentication flow.\n#ee.Authenticate()\n\n# Initialize the library.\nee.Initialize()\n\n\n# Read US watersheds using hydrologic unit codes (HUC)\nwatersheds = ee.FeatureCollection(\"USGS/WBD/2017/HUC12\")\nmcdowell_creek = watersheds.filter(ee.Filter.eq('huc12', '102701010204')).first().geometry()\nmcdowell_creek_geom = mcdowell_creek.getInfo()\n\n\n# Get collection for Terra Vegetation Indices 16-Day Global 500m\nstart_date = '2021-01-01'\nend_date = '2022-12-31'\ncollection = ee.ImageCollection('MODIS/006/MOD13A1') \\\n               .filterDate(start_date, end_date) \\\n               .select('EVI')\n\nThe enxt step is to create a function that will be applied to each image of the ImageCollection. The function will aggregate all the pixels in the region of interest into a single average value. Since each image represent a day, the resulting average value will be associated with the date of the image, so that then we can create a time series.\n\n# Function to apply reduceRegion to each image and extract the areal average EVI.\ndef compute_mean_evi(image):\n    mean_evi = image.reduceRegion(\n        reducer=ee.Reducer.mean(),\n        geometry=mcdowell_creek,\n        scale=500,\n        maxPixels=1e9\n    )\n    \n    # Get the date of the image.\n    date = image.date().format('YYYY-MM-dd')\n    \n    # Return a Feature with properties for mean EVI and date.\n    #return ee.Feature(None, {'meanEVI': mean_evi.get('EVI'), 'date': date})\n    return ee.Feature(None, {'EVI_avg': mean_evi.get('EVI'), 'date': date})\n\n# Map the function over the collection. \nevi_means = collection.map(compute_mean_evi) # This is a feature collection\n\n\n# Convert the resulting Feature Collection to a list of dictionaries.\nreducer = ee.Reducer.toList(2)\nselector = ['date','EVI_avg']\nevi_data_list = evi_means.reduceColumns(reducer, selector).values().getInfo()\n\n\n# Convert the list of data to a pandas DataFrame for easy handling and visualization.\ndf = pd.DataFrame(np.squeeze(evi_data_list), columns=['date','EVI_avg']).dropna()\n\n# Apply factor to EVI\ndf['EVI_avg'] = df['EVI_avg'].astype(float) * 0.0001\n\n# Convert dates to datetime format\ndf['date'] = pd.to_datetime(df['date'])\n\n# Display a few rows\ndf.head(3)\n\n\n\n\n\n\n\n\ndate\nEVI_avg\n\n\n\n\n0\n2021-01-01\n0.197894\n\n\n1\n2021-01-17\n0.173088\n\n\n2\n2021-02-02\n0.170202\n\n\n\n\n\n\n\n\n# Create figure\nplt.figure(figsize=(8,3))\nplt.title('Kings Creek watershed 2022')\nplt.plot(df['date'], df['EVI_avg'])\nplt.ylabel('Enhanced Vegetation Index')\nplt.show()"
  },
  {
    "objectID": "notebooks/reduce_image_collection_to_timeseries.html#example-2-mean-ground-water-anomaly-for-entire-aquifer",
    "href": "notebooks/reduce_image_collection_to_timeseries.html#example-2-mean-ground-water-anomaly-for-entire-aquifer",
    "title": "8  Reduce collection to time series",
    "section": "Example 2: Mean ground water anomaly for entire aquifer",
    "text": "Example 2: Mean ground water anomaly for entire aquifer\nThe Gravity Recovery and Climate Experiment (GRACE) mission utilizes a pair of satellites in tandem orbit to measure small variations in Earth’s gravitational pull. These variations are caused by changes in mass distribution, including water moving through the Earth’s system. As water accumulates or depletes in an area, such as in an aquifer, it alters the region’s gravitational attraction, which GRACE detects.\nThe application of GRACE data has been crucial in monitoring the Ogallala Aquifer, one of the largest aquifers in the world, stretching across eight states in the United States. Over-reliance on this aquifer for agricultural irrigation, municipal, and industrial water has led to substantial depletion in water levels. By capturing the changes in gravitational pull over the Ogallala region, GRACE has provided researchers and policymakers with essential data on the aquifer’s depletion rates.\n\n# Read boundary of Ogalla Aquifer\nwith open('../datasets/ogallala_aquifer_bnd.geojson') as file:\n    roi_json = json.load(file)\n\n# Define the ee.Geometry\nroi = ee.Geometry(roi_json['features'][0]['geometry'])\n\n# Create mask\nmask = ee.Image.constant(1).clip(roi).mask()\n\n\n# Get GRACE equivalent water thickeness anomaly \ngrace = ee.ImageCollection('NASA/GRACE/MASS_GRIDS/LAND') \\\n                  .filterDate('2002-04-01', '2017-01-07') \\\n                  .filterBounds(roi) \\\n                  .select('lwe_thickness_csr')\n\n\n# Create function to apply the reduceRegion() method to each image\ndef compute_mean_water(image):\n    mean_water = image.reduceRegion(\n        reducer=ee.Reducer.mean(),\n        geometry=roi,\n        scale=100_000,\n        maxPixels=1e9\n    )\n    \n    # Get the date of the image.\n    date = image.date().format('YYYY-MM-dd')\n    \n    # Return a Feature with properties for mean water thickness and date.\n    return ee.Feature(None, {'water_thickness_avg':mean_water.get('lwe_thickness_csr'),\n                             'date': date})\n\n\n# Apply the created function to each image in the collection\n# This operation results in a FeatureCollection\nmean_water_thickness = grace.map(compute_mean_water)\n\n\n# Convert the resulting Feature Collection to a list of dictionaries.\nreducer = ee.Reducer.toList(2)\nselector = ['date','water_thickness_avg']\ndata_list = mean_water_thickness.reduceColumns(reducer, selector).getInfo()\n\n\n# Convert the list of data to a pandas DataFrame for easy handling and visualization.\ndf = pd.DataFrame(np.squeeze(data_list['list']), \n                  columns=['date','water_thickness_avg']).dropna()\n\n# Convert dates to datetime format\ndf['date'] = pd.to_datetime(df['date'])\n\ndf['water_thickness_avg'] = df['water_thickness_avg'].astype(float)\n\n# Display a few rows\ndf.head(3)\n\n\n\n\n\n\n\n\ndate\nwater_thickness_avg\n\n\n\n\n0\n2002-04-01\n7.638767\n\n\n1\n2002-05-01\n7.061499\n\n\n2\n2002-08-01\n-2.686608\n\n\n\n\n\n\n\n\n# Create figure\nplt.figure(figsize=(8,3))\nplt.title('Ogallala aquifer')\nplt.plot(df['date'], df['water_thickness_avg'])\nplt.ylabel('Equivalent Water Thickness Anomaly')\nplt.show()"
  },
  {
    "objectID": "notebooks/use_my_vector_file.html#references",
    "href": "notebooks/use_my_vector_file.html#references",
    "title": "9  Use my vector data",
    "section": "References",
    "text": "References\n\nWalkinshaw, M., O’Geen, A., & Beaudette, D. (2021). Soil properties. California Soil Resource Lab."
  },
  {
    "objectID": "notebooks/band_computations.html",
    "href": "notebooks/band_computations.html",
    "title": "10  Band computations",
    "section": "",
    "text": "Active and passive remote sensors onboard orbitting satellites usually collect multiple spectral bands. The combination of several of these bands can often be used to characterize land surface features, like vegetation, water bodies, and wildfires.\nIn this example we will use the red and near infrared bands from Sentinel 2 satellite of the European Space Agency to compute the normalized difference vegetation index at 10-meter spatial resolution for a production field in Argentina.\n\n# Import modules\nimport ee\nimport json\nimport requests\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport xarray as xr\nimport pandas as pd\n\n\n# Authenticate\n#ee.Authenticate()\n\n# Initialize API\nee.Initialize()\n\n\n# Import boundary for area of interest (aoi)\nwith open('../datasets/field_bnd_carmen.geojson') as file:\n    aoi_json = json.load(file)\n\n# Define the ee.Geometry\naoi = ee.Geometry(aoi_json['features'][0]['geometry'])\n\n# Create mask for field\nmask = ee.Image.constant(1).clip(aoi).mask()\n\n\n# Define start and end dates\n# Summer for southern hemisphere, matching the soybean growing season\nstart_date = '2023-01-10'\nend_date = '2023-01-30'\n\n\n# Load Sentinel-2 image collection\nS2 = ee.ImageCollection('COPERNICUS/S2') \\\n                .filterDate(start_date, end_date) \\\n                .filterBounds(aoi) \\\n                .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \\\n                .select(['B8', 'B4'])  # B8 is NIR, B4 is Red\n\n\n# Print the following line to explore the selected images\n#S2.getInfo()['features']\n\n\ndef calculate_ndvi(image):\n    \"\"\"\n    Function to calculate NDVI for a single image.\n    \"\"\"\n    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n    return image.addBands(ndvi)\n\n# Apply the NDVI function to each image in the collection\nndvi_collection = S2.map(calculate_ndvi)\n\n\n# Apply the function to add mean NDVI as a property\nndvi_mean = ndvi_collection.reduce(ee.Reducer.mean())\n\n# Mask ndvi image\nndvi_mean = ndvi_mean.mask(mask)\n\n\n# Inspect resulting image (note the the new band is \"NDVI_mean\"\nndvi_mean.select('NDVI_mean').getInfo()\n\n{'type': 'Image',\n 'bands': [{'id': 'NDVI_mean',\n   'data_type': {'type': 'PixelType',\n    'precision': 'float',\n    'min': -1,\n    'max': 1},\n   'crs': 'EPSG:4326',\n   'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n\n\n\n# Get url link for image\nimage_url = ndvi_mean.getDownloadUrl({'region': aoi,'scale':10,\n                                      'bands':['NDVI_mean'],\n                                     'crs': 'EPSG:4326', \n                                     'format': 'GEO_TIFF'})\n    \n# Request data using URL and save data as a new GeoTiff file\nresponse = requests.get(image_url)\n\n# Save geotiff image to local drive\nfilename = '../outputs/field_carmen_ndvi.tif'\nwith open(filename, 'wb') as f:\n    f.write(response.content)\n\n\n# Read saved geotiff image from local drive\nndvi_raster = xr.open_dataarray(filename).squeeze()\n\n\ndf = pd.DataFrame(aoi_json['features'][0]['geometry']['coordinates'][0])\ndf.columns = ['lon','lat']\ndf.head(3)\n\n\n\n\n\n\n\n\nlon\nlat\n\n\n\n\n0\n-61.792900\n-33.750588\n\n\n1\n-61.790372\n-33.753893\n\n\n2\n-61.784847\n-33.750976\n\n\n\n\n\n\n\n\n# Create colormap\nhex_palette = ['#FEFEFE','#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901',\n             '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01',\n             '#012E01', '#011D01', '#011301']\n\n# Use the built-in ListedColormap function to do the conversion\nrgb_cmap = colors.ListedColormap(hex_palette)\n\n\n# Create figure\nndvi_raster.plot.imshow(figsize=(8,4), cmap=rgb_cmap, add_colorbar=True,\n                   cbar_kwargs={'label':'NDVI'})\n\nplt.plot(df['lon'], df['lat'],'-k')\nplt.title('Field NDVI')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.tight_layout()\nplt.show()\n\n\n\n\nWe can also get the NDVI values and corresponding coordinates to create a contour plot to delineate areas of higher and lower vegetation values.\n\n# Give arrays a shorter name\nX = ndvi_raster.coords['x']\nY = ndvi_raster.coords['y']\nZ = ndvi_raster.values\n        \nplt.figure()\nplt.plot(df['lon'], df['lat'],'-k', linewidth=2)\nplt.contour(X, Y, Z, levels=8, linewidths=0.5, colors='k')\nplt.contourf(X, Y, Z, levels=8, cmap='Spectral')\nplt.colorbar(label='NDVI')\nplt.xticks(rotation=15)\nplt.show()"
  },
  {
    "objectID": "notebooks/animate_image_collection.html#example-1-animation-of-vegetation-dynamics-in-the-cloud",
    "href": "notebooks/animate_image_collection.html#example-1-animation-of-vegetation-dynamics-in-the-cloud",
    "title": "11  Animate image collection",
    "section": "Example 1: Animation of vegetation dynamics in the cloud",
    "text": "Example 1: Animation of vegetation dynamics in the cloud\n\nDefine animation area\n\n# Define a rectangular region over the state of Kansas\n# Rectangle coordinates: xMin, yMin, xMax, yMax\nrect = ee.Geometry.Rectangle([[-102.5,36.5], [-94,40.5]]);\n\n\n# Select state boundary\n# For countries you can use: FAO/GAUL_SIMPLIFIED_500m/2015/level1\n# A site with country codes: http://www.statoids.com/wab.html\nregion = ee.FeatureCollection(\"TIGER/2018/States\").filter(ee.Filter.eq('NAME', 'Kansas'))\n\n\n\nRetrieve vegetation product\n\n# Select a collection from the available dataset\nstart_date = '2012-01-01'\nend_date = '2022-01-01'\nmodis = ee.ImageCollection('MODIS/006/MOD13A2').filterDate(start_date, end_date)\ncollection = modis.select('NDVI').map(lambda img: img.clip(region))\n\n\n\nGet day of the year for each image\nIn this step we define a function that is applied to each image of the collection using the map() method. The function computes the day of the year based on the date, and adds this variable to each image as a property. Since each image of the collection remains the same, except that each image now includes the day of the year (doy), we overwrite the collection with the updated version of itself.\n\n# Define function\ndef get_doy(img):\n    \"\"\"\n    Function that finds and adds the day of the year\n    to each image in the collection.\n    \"\"\"\n    doy = ee.Date(img.get('system:time_start')).getRelative('day', 'year')\n    return img.set('doy', doy)\n\n# Apply the function to each image of the collection using the .map() method\ncollection = collection.map(get_doy)\n\n# The `doy` is added to the properties of each image\n# Use the following line to see the added property\n# collection.getInfo()\n\n\n# Filter the complete collection to a single year of data e.g. 2021.\n# We use one year as a dummy variable to compute the day of the year.\nunique_doy = collection.filterDate('2021-01-01', '2022-01-01')\n\n\n# Define a filter that identifies which images from the complete collection\n# match the DOY of the unique DOY variable.\n# leftField == rightField\nfilt = ee.Filter.equals(leftField='doy', rightField='doy')\n\n\n# Define a join.\njoin = ee.Join.saveAll('doy_matches')\n\n# Apply the join and convert the resulting FeatureCollection to an ImageCollection.\njoin_col = ee.ImageCollection(join.apply(unique_doy, collection, filt))\n\n\n\nReduce all images for a given DOY pixel-wise.\n\n# Define median reducer for images of the same DOY\ndef apply_median(img):\n    \"\"\"\n    Function that computes the pixel-wise median\n    for all images matching a given DOY\n    \"\"\"\n    doy_col = ee.ImageCollection.fromImages(img.get('doy_matches'))\n    return doy_col.reduce(ee.Reducer.median()).multiply(0.0001)\n\n# Apply function for each DOY and for all images matching a given DOY\ncomposite = join_col.map(apply_median)\n\n\n\nCreate animation\n\n# Define function that handles the visuals (paint adds the boundary, \n# which is a assigned a value (-0.1) relative to the other pixels (so a low value means red here).\ndef animate(img):\n    cmap = ['black','FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163', '99B718', '74A901',\n        '66A000', '529400', '3E8601', '207401', '056201', '004C00', '023B01',\n        '012E01', '011D01', '011301']\n    frame = img.paint(region, -0.1, 2).visualize(min=-0.1, max=0.8, palette=cmap)\n    return frame\n\n# Map the function to each image\nanimation = composite.map(animate)\n\n\n# Animation options\nanimationOptions = {'region': rect,     # Selected region on the map\n                    'dimensions': 600,    # Size of the animation\n                    'crs': 'EPSG:3857',   # Coordinate reference system\n                    'framesPerSecond': 6  # Animation speed\n}\n\n\n# Render the GIF animation in the console.\nprint(animation.getVideoThumbURL(animationOptions))\n\nhttps://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/videoThumbnails/dab1527ad8bdb39bc2937c68ffaa4f5a-444f7489b454a5e458a7b3773c598bee:getPixels\n\n\n\n# Right click on the generated GIF image in the browser and select \"save image as\" to download it."
  },
  {
    "objectID": "notebooks/animate_image_collection.html#example-2-animation-of-vegetation-dynamics-in-local-disk",
    "href": "notebooks/animate_image_collection.html#example-2-animation-of-vegetation-dynamics-in-local-disk",
    "title": "11  Animate image collection",
    "section": "Example 2: Animation of vegetation dynamics in local disk",
    "text": "Example 2: Animation of vegetation dynamics in local disk\nThis option requires downloading the images to the local drive and creating the animation ourselves, but it provides with the greatest flexibilty to edit the resulting animation.\n\n# Import additional modules\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom matplotlib import colors\n\n\n# Define function to save images to the local drive \ndef save_geotiff(ee_image, filename, crs, scale, geom, bands=[]):\n    \"\"\"\n    Function to save images from Google Earth Engine into local hard drive.\n    \"\"\"\n    image_url = ee_image.getDownloadUrl({'region': geom,'scale':scale, \n                                         'bands': bands,\n                                         'crs': f'EPSG:{crs}', \n                                         'format': 'GEO_TIFF'})\n    \n    # Request data using URL and save data as a new GeoTiff file\n    response = requests.get(image_url)\n    with open(filename, 'wb') as f:\n        f.write(response.content)\n        return print(f\"Saved image {filename}\")\n\n\n# Select \nregion = ee.FeatureCollection(\"TIGER/2018/States\").filter(ee.Filter.eq('NAME', 'Kansas'))\n\n# Create mask\nmask = ee.Image.constant(1).clip(region).mask()\n\n\n# Define the time range\nstart_date = '2022-01-01'\nend_date = '2022-12-31'\n\n# Select MODIS Terra Vegetation Indices 16-Day Global 1km\nmodis = ee.ImageCollection(\"MODIS/061/MOD13A2\").filterDate(start_date, end_date)\ncollection = modis.select('NDVI')\n\n# Get the list of available image dates\nget_date = lambda image: ee.Image(image).date().format('YYYY-MM-dd')\n\ndates = collection.toList(collection.size()).map(get_date).getInfo()\nprint(dates)\n\n['2022-01-01', '2022-01-17', '2022-02-02', '2022-02-18', '2022-03-06', '2022-03-22', '2022-04-07', '2022-04-23', '2022-05-09', '2022-05-25', '2022-06-10', '2022-06-26', '2022-07-12', '2022-07-28', '2022-08-13', '2022-08-29', '2022-09-14', '2022-09-30', '2022-10-16', '2022-11-01', '2022-11-17', '2022-12-03', '2022-12-19']\n\n\n\ngif_folder = '../outputs/ndvi_gif_files'\nif not glob.os.path.isdir(gif_folder):\n    glob.os.mkdir(gif_folder)\n\n\nfor date in dates:\n    start_date = date\n    end_date = (datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')\n    ndvi_img = ee.ImageCollection('MODIS/006/MOD13A2').filterDate(start_date, end_date).first()\n    ndvi_img = ndvi_img.multiply(0.0001).clip(region).mask(mask)\n    \n    filename = f\"{gif_folder}/ndvi_{date}.tiff\"\n    try:\n        save_geotiff(ndvi_img, filename, crs=4326, scale=1000, geom=region.geometry(), bands=['NDVI'])\n    except:\n        print(f\"Trouble loading image {filename}. Skipping this image.\")\n\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-01-01.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-01-17.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-02-02.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-02-18.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-03-06.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-03-22.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-04-07.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-04-23.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-05-09.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-05-25.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-06-10.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-06-26.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-07-12.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-07-28.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-08-13.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-08-29.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-09-14.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-09-30.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-10-16.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-11-01.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-11-17.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-12-03.tiff\nSaved image ../outputs/ndvi_gif_files/ndvi_2022-12-19.tiff\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the method .filterDate(start_date, end_date) the start date is inclusive, but the end date is exclusive.\n\n\n\n# Read the list of images\nimages = glob.glob(f\"{gif_folder}/*.tiff\")\nimages.sort()\n\n\n# Paletter of colors for the Enhanced Vegetation Index\nhex_palette = ['#FF69B4','#CE7E45', '#DF923D', '#F1B555', '#FCD163', '#99B718', '#74A901',\n             '#66A000', '#529400', '#3E8601', '#207401', '#056201', '#004C00', '#023B01',\n             '#012E01', '#011D01', '#011301']\n\n# Use the built-in ListedColormap function to do the conversion\ncmap = colors.ListedColormap(hex_palette)\n\n\n\n\n\n\n\nColormap note\n\n\n\nThe first color of the palette is hot pink (‘#FF69B4’). The color was added to represent the lowest NDVI values, which are typically caused by snow on the ground during winter months.\n\n\n\n# Create figure\nfig, ax = plt.subplots(figsize=(6,3))\n\n# Leave a bit more room at the bottom to avoid cutting the xlabel\nfig.subplots_adjust(bottom=0.15)\n\n\n# Create figure with axes and colorbar, which will remain fixed.\nraster = xr.open_dataarray(images[0]).squeeze()\nraster.plot.imshow(ax=ax, cmap=cmap, add_colorbar=True, \n                   cbar_kwargs={'label':'NDVI'},vmin=0, vmax=0.8)\n\ndef animate(index):\n    \"\"\"\n    Function that creates each frame.\n    \"\"\"\n    \n    # Read geotiff image with xarray\n    raster = xr.open_dataarray(images[index]).squeeze()\n    \n    # Clear axes and draw new objects (without colorbar)\n    # Force vmin and vmax to keep the same range of values as the colorbar\n    ax.clear()\n    raster.plot.imshow(ax=ax, cmap=cmap, add_colorbar=False, vmin=0, vmax=0.8)\n    ax.set_title(images[index][-15:-5])\n    ax.set_xlabel('Longitude')\n    ax.set_ylabel('Latitude')\n    plt.tight_layout()\n\n    return ax\n\n# Avoid displaying the first figure\nplt.close()\n\n# Save animation as .gif\nani = animation.FuncAnimation(fig, animate, len(images),interval=250)\nani.save('../outputs/ndvi_animation.gif', writer='pillow') \n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\nHere is the resulting gif. Note that during the winter the image occasionally shows some areas with snow on the ground (look for reddish patches). You can display it in your notebook using the following html code:\n&lt;img src=\"../outputs/ndvi_animation.gif\" alt=\"drawing\" width=\"650\"/&gt;"
  },
  {
    "objectID": "notebooks/animate_image_collection.html#example-3-soil-moisture-dynamics",
    "href": "notebooks/animate_image_collection.html#example-3-soil-moisture-dynamics",
    "title": "11  Animate image collection",
    "section": "Example 3: Soil moisture dynamics",
    "text": "Example 3: Soil moisture dynamics\n\n# Since the product is available every 3 hours, define one month only\n# to avoid running hitting the GEE memory limit\nstart_date = '2023-01-01'\nend_date = '2023-01-31'\n\n# Select SMAP Level 3 layer at 9-km spatial resolution\nsmap = ee.ImageCollection('NASA/SMAP/SPL4SMGP/007')\n\n# Get the list of available image dates\nget_date = lambda image: ee.Image(image).date().format('YYYY-MM-dd HH:mm:SS')\n\ncollection = smap.filterDate(start_date, end_date)\ndates = collection.toList(collection.size()).map(get_date).getInfo()\nprint(len(dates))\nprint(dates[0:10])\n\n240\n['2023-01-01 01:30:00', '2023-01-01 04:30:00', '2023-01-01 07:30:00', '2023-01-01 10:30:00', '2023-01-01 13:30:00', '2023-01-01 16:30:00', '2023-01-01 19:30:00', '2023-01-01 22:30:00', '2023-01-02 01:30:00', '2023-01-02 04:30:00']\n\n\n\nsmap_gif_folder = '../outputs/smap_gif_files'\nif not glob.os.path.isdir(smap_gif_folder):\n    glob.os.mkdir(smap_gif_folder)\n\n\n# Use pandas to create range of dates\ndates = pd.date_range('2023-01-01', '2023-12-31', freq='7D')\ndates\n\nDatetimeIndex(['2023-01-01', '2023-01-08', '2023-01-15', '2023-01-22',\n               '2023-01-29', '2023-02-05', '2023-02-12', '2023-02-19',\n               '2023-02-26', '2023-03-05', '2023-03-12', '2023-03-19',\n               '2023-03-26', '2023-04-02', '2023-04-09', '2023-04-16',\n               '2023-04-23', '2023-04-30', '2023-05-07', '2023-05-14',\n               '2023-05-21', '2023-05-28', '2023-06-04', '2023-06-11',\n               '2023-06-18', '2023-06-25', '2023-07-02', '2023-07-09',\n               '2023-07-16', '2023-07-23', '2023-07-30', '2023-08-06',\n               '2023-08-13', '2023-08-20', '2023-08-27', '2023-09-03',\n               '2023-09-10', '2023-09-17', '2023-09-24', '2023-10-01',\n               '2023-10-08', '2023-10-15', '2023-10-22', '2023-10-29',\n               '2023-11-05', '2023-11-12', '2023-11-19', '2023-11-26',\n               '2023-12-03', '2023-12-10', '2023-12-17', '2023-12-24',\n               '2023-12-31'],\n              dtype='datetime64[ns]', freq='7D')\n\n\n\n# Only use weekly moisture levels to avoid retrieving tons of images\n\nfor date in dates:\n    start_date = date.strftime('%Y-%m-%d')\n    end_date = (date + pd.Timedelta('1D')).strftime('%Y-%m-%d')\n    \n    # Request data and create average of all images for that day\n    smap_img = smap.filterDate(start_date, end_date) \\\n                   .reduce(ee.Reducer.mean()).multiply(100).clip(region).mask(mask)\n        \n    try:\n        # Creaoutput file name\n        filename = f\"{smap_gif_folder}/smap_{start_date}.tiff\"\n    \n        # Note that the band name has `mean` appended since that is the reducer we used\n        # I also donwscaled the map to 1 km resolution from 9 km\n        save_geotiff(smap_img, filename, crs=4326, scale=9000, \n                     geom=region.geometry(), bands=['sm_profile_mean'])\n    \n    except:\n        print(f\"Trouble loading image {filename}. Skipping this image.\")\n\n\n\n\n\n\n\nNote\n\n\n\nIn the method .filterDate(start_date, end_date) the start date is inclusive, but the end date is exclusive.\n\n\n\n# Read the list of images\nimages = glob.glob(f\"{smap_gif_folder}/*.tiff\")\nimages.sort()\n\n\n# Define colormap\ncmap = 'Spectral'\n\n# Create figure\nfig, ax = plt.subplots(figsize=(6,3))\n\n# Leave a bit more room at the bottom to avoid cutting the xlabel\nfig.subplots_adjust(bottom=0.15)\n\n# Create figure with axes and colorbar, which will remain fixed.\nraster = xr.open_dataarray(images[0]).squeeze()\nraster.plot.imshow(ax=ax, cmap=cmap, add_colorbar=True, \n                   cbar_kwargs={'label':'VWC (%)'}, vmin=0, vmax=40)\n\ndef animate(index):\n    \"\"\"\n    Function that creates each frame.\n    \"\"\"\n    \n    # Read geotiff image with xarray\n    raster = xr.open_dataarray(images[index]).squeeze()\n    \n    # Clear axes and draw new objects (without colorbar)\n    # Force vmin and vmax to keep the same range of values as the colorbar\n    ax.clear()\n    raster.plot.imshow(ax=ax, cmap=cmap, add_colorbar=False, vmin=0, vmax=40)\n    ax.set_title(images[index][-15:-5])\n    ax.set_xlabel('Longitude')\n    ax.set_ylabel('Latitude')\n    plt.tight_layout()\n\n    return ax\n\n# Avoid displaying the first figure\nplt.close()\n\n# Save animation as .gif\nani = animation.FuncAnimation(fig, animate, len(images), interval=250)\nani.save('../outputs/smap_animation.gif', writer='pillow') \n\n&lt;Figure size 640x480 with 0 Axes&gt;"
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#habitat-fragmentation-problem",
    "href": "notebooks/integrate_with_geopandas.html#habitat-fragmentation-problem",
    "title": "12  Integrate with GeoPandas",
    "section": "Habitat fragmentation problem",
    "text": "Habitat fragmentation problem\nThe Flint Hills is a region is one of the last remaining tallgrass prairies in North America. This unique ecosystem is home to a rich biodiversity, including numerous grassland bird species, diverse plant life, and a variety of other wildlife. The Flint Hills have resisted the plow thanks to their rocky terrain, preserving an expanse of native grasslands that once covered much of the Great Plains. This area not only offers a glimpse into America’s natural heritage but also serves as a critical refuge for species that thrive in the prairie habitat.\nHabitat fragmentation is a process where large continuous habitats are divided into smaller, isolated sections. Habitat fragmentation is a significant ecological concern, particularly in regions like the Flint Hills. Roads, one of the primary drivers of such fragmentation, can disrupt the interconnected landscapes, limiting animal movement, altering animal behavior, and increasing vulnerability to external threats like invasive species and climate change. In the Flint Hills, the expansion of road networks could potentially threaten the integrity of this pristine habitat.\nIn this exercise we explore some of the fragmentation caused by primary and secondary roads.\n\n# Import modules\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap, BoundaryNorm\nimport geopandas as gpd\nimport requests\nimport xarray as xr\nimport ee\n\n\n\n# Authenticate GEE\n#ee.Authenticate()\n\n# Initialize GEE\nee.Initialize()\n\n\n# Define CRS\nutm14 = 32614 # UTM 14 projected coordinates in meters (good for Kansas)\nwgs84 = 4326 # WGS84 geographic coordinates"
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#load-boundary-of-flint-hills-ecological-region",
    "href": "notebooks/integrate_with_geopandas.html#load-boundary-of-flint-hills-ecological-region",
    "title": "12  Integrate with GeoPandas",
    "section": "Load boundary of Flint Hills ecological region",
    "text": "Load boundary of Flint Hills ecological region\n\n# Load eco regions\neco_regions = ee.FeatureCollection(\"RESOLVE/ECOREGIONS/2017\")\n\n# Use this line to inspect properties\n#eco_regions.first().propertyNames().getInfo()\n\n\n# Select flint hills region\n# Find ecoregion ID using their website: https://ecoregions.appspot.com\nregion = eco_regions.filter(ee.Filter.inList('ECO_ID',[392]))\nregion_data = region.getInfo()\n\n\n# Convert to GeoDataframe\ngdf_region = gpd.GeoDataFrame.from_features(region_data['features'], crs=wgs84)\ngdf_region['geometry'] = gdf_region['geometry'].simplify(0.001)\ngdf_region.head()\n\n\n\n\n\n\n\n\ngeometry\nBIOME_NAME\nBIOME_NUM\nCOLOR\nCOLOR_BIO\nCOLOR_NNH\nECO_BIOME_\nECO_ID\nECO_NAME\nLICENSE\nNNH\nNNH_NAME\nOBJECTID\nREALM\nSHAPE_AREA\nSHAPE_LENG\n\n\n\n\n0\nPOLYGON ((-97.36772 38.37556, -97.36465 38.359...\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116"
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#load-primary-and-secondary-roads",
    "href": "notebooks/integrate_with_geopandas.html#load-primary-and-secondary-roads",
    "title": "12  Integrate with GeoPandas",
    "section": "Load primary and secondary roads",
    "text": "Load primary and secondary roads\n\n# Load TIGER roads dataset\nroads_dataset = ee.FeatureCollection('TIGER/2016/Roads').filterBounds(region)\nselected_roads = roads_dataset.filter(ee.Filter.inList('mtfcc',['S1100','S1200']))\nroads_data = selected_roads.getInfo()\n\n# Use this line to see available properties\n# https://www2.census.gov/geo/pdfs/reference/mtfccs2017.pdf\n# roads_dataset.first().propertyNames().getInfo()\n\n\n# Convert Geodataframe\ngdf_roads = gpd.GeoDataFrame.from_features(roads_data['features'], crs=wgs84)\ngdf_roads.head()\n\n\n\n\n\n\n\n\ngeometry\nfullname\nlinearid\nmtfcc\nrttyp\n\n\n\n\n0\nLINESTRING (-96.64559 39.84213, -96.64558 39.8...\nUS Hwy 77\n1103942688564\nS1200\nU\n\n\n1\nLINESTRING (-96.66120 36.78194, -96.66182 36.7...\n1st St\n110788715400\nS1200\nM\n\n\n2\nLINESTRING (-96.65110 36.94044, -96.65108 36.9...\nHwy 18\n1103942486000\nS1200\nM\n\n\n3\nLINESTRING (-96.65181 36.93269, -96.65178 36.9...\nBroadway\n110788721819\nS1200\nM\n\n\n4\nLINESTRING (-96.65110 36.94044, -96.65108 36.9...\nBroadway\n1103942485999\nS1200\nM\n\n\n\n\n\n\n\n\n# Show map\nfig, ax = plt.subplots(1,1, figsize=(3,6))\ngdf_region.plot(ax=ax, facecolor='None')\ngdf_roads.plot(ax=ax, color='tomato')"
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#unify-roads-into-single-multiline-feature",
    "href": "notebooks/integrate_with_geopandas.html#unify-roads-into-single-multiline-feature",
    "title": "12  Integrate with GeoPandas",
    "section": "Unify roads into single Multiline feature",
    "text": "Unify roads into single Multiline feature\n\nunified_roads = gdf_roads.unary_union\ngdf_unified_roads = gpd.GeoDataFrame(geometry=[unified_roads], crs=gdf_roads.crs)\ngdf_unified_roads['geometry'] = gdf_unified_roads['geometry'].simplify(0.001)\ngdf_unified_roads.head()\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nMULTILINESTRING ((-96.64559 39.84213, -96.6435..."
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#create-buffer-area-around-roads",
    "href": "notebooks/integrate_with_geopandas.html#create-buffer-area-around-roads",
    "title": "12  Integrate with GeoPandas",
    "section": "Create buffer area around roads",
    "text": "Create buffer area around roads\nThis step is needed to be able to compute intersection and difference with the boundary map. We will assign a buffer of 1 km on each side of each road to create clearly distinct polygons. If you work in smaller areas, a smaller buffer would be better. In this dataset, a couple of kilometers represents a small magnitude compared to the extent of the region.\n\n# Create buffer as a GeoSeries\nbuffer_distance = 1000  # Example buffer distance\nbuffered_unified_roads = gdf_unified_roads.to_crs(utm14).buffer(buffer_distance).to_crs(gdf_roads.crs)\n\n\n# Create a new GeoDataFrame with the buffered unified roads geometry\ngdf_buffered_unified_roads = gpd.GeoDataFrame(geometry=gpd.GeoSeries(buffered_unified_roads),\n                                              crs=gdf_roads.crs)\n\ngdf_buffered_unified_roads.head()\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nMULTIPOLYGON (((-97.36906 38.91970, -97.37023 ..."
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#obtained-fragmented-areas",
    "href": "notebooks/integrate_with_geopandas.html#obtained-fragmented-areas",
    "title": "12  Integrate with GeoPandas",
    "section": "Obtained fragmented areas",
    "text": "Obtained fragmented areas\nThe key operation in this step is to compute the `difference between layers.\n\n# Obtained fragmented areas\nfragmented_regions = gpd.overlay(gdf_region, gdf_buffered_unified_roads, how='difference')\nfragmented_regions.head()\n\n\n\n\n\n\n\n\ngeometry\nBIOME_NAME\nBIOME_NUM\nCOLOR\nCOLOR_BIO\nCOLOR_NNH\nECO_BIOME_\nECO_ID\nECO_NAME\nLICENSE\nNNH\nNNH_NAME\nOBJECTID\nREALM\nSHAPE_AREA\nSHAPE_LENG\n\n\n\n\n0\nMULTIPOLYGON (((-95.99115 39.43608, -95.91121 ...\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116\n\n\n\n\n\n\n\n\n# Explode the multipolygon feature\ngdf_patches = fragmented_regions.explode(index_parts=True).reset_index(drop=True)\ngdf_patches.head()\n\n\n\n\n\n\n\n\nBIOME_NAME\nBIOME_NUM\nCOLOR\nCOLOR_BIO\nCOLOR_NNH\nECO_BIOME_\nECO_ID\nECO_NAME\nLICENSE\nNNH\nNNH_NAME\nOBJECTID\nREALM\nSHAPE_AREA\nSHAPE_LENG\ngeometry\n\n\n\n\n0\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116\nPOLYGON ((-95.99115 39.43608, -95.91121 39.396...\n\n\n1\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116\nPOLYGON ((-96.06161 38.08792, -96.05381 38.080...\n\n\n2\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116\nPOLYGON ((-95.87537 37.82449, -95.88215 37.819...\n\n\n3\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116\nPOLYGON ((-95.90649 38.95669, -95.90651 38.942...\n\n\n4\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116\nPOLYGON ((-95.94060 39.01776, -95.93234 39.001...\n\n\n\n\n\n\n\n\n# Compute area and find patch with largest area\ngdf_patches['area'] = gdf_patches.to_crs(utm14).area\nidx_largest_area = gdf_patches['area'].argmax()\n\n\n# Plot fragmented areas\nfig, ax = plt.subplots(figsize=(10, 10))\ngdf_patches.plot(ax=ax, alpha=0.75, linewidth=0.5, cmap='tab20', edgecolor='black')\ngdf_patches.loc[[idx_largest_area],'geometry'].plot(ax=ax, edgecolor='red', linewidth=3)\n\nplt.show()"
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#load-cropland-datalayer",
    "href": "notebooks/integrate_with_geopandas.html#load-cropland-datalayer",
    "title": "12  Integrate with GeoPandas",
    "section": "Load cropland datalayer",
    "text": "Load cropland datalayer\nThis layer will help us understand which polygons are dominated by cropland and which polygons are still dominated by grassland vegetation\n\n# Land use\ncdl = ee.ImageCollection('USDA/NASS/CDL')\ncdl_layer = cdl.filter(ee.Filter.date('2020-01-01', '2021-12-31')).first().clip(region)\ncropland = cdl_layer.select('cropland')\n\n# Single-band GeoTIFF files wrapped in a zip file.\nurl = cropland.getDownloadUrl({\n    'region': region.geometry(),\n    'scale':100,\n    'format': 'GEO_TIFF'\n})\n\n\n# Request data using URL and save data as a new GeoTiff file\nresponse = requests.get(url)\nwith open('../datasets/spatial/cropland.tif', 'wb') as f:\n    f.write(response.content)\n\n\n# Read GeoTiff file using the Xarray package\nraster = xr.open_dataarray('../datasets/spatial/cropland.tif').squeeze()\nraster = raster.rio.reproject(wgs84)\n\n\n# Examine raster file\nraster\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'band_data' (y: 3560, x: 1658)&gt;\narray([[ nan,  nan,  nan, ...,  37.,  37., 176.],\n       [ nan,  nan,  nan, ..., 111., 111.,   5.],\n       [ nan,  nan,  nan, ...,  37.,  37.,   5.],\n       ...,\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan]], dtype=float32)\nCoordinates:\n  * x            (x) float64 -97.39 -97.39 -97.39 ... -95.86 -95.86 -95.86\n  * y            (y) float64 39.72 39.72 39.72 39.72 ... 36.43 36.43 36.43 36.43\n    band         int64 1\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:           Area\n    TIFFTAG_RESOLUTIONUNIT:  1 (unitless)\n    TIFFTAG_XRESOLUTION:     1\n    TIFFTAG_YRESOLUTION:     1xarray.DataArray'band_data'y: 3560x: 1658nan nan nan nan nan nan nan nan ... nan nan nan nan nan nan nan nanarray([[ nan,  nan,  nan, ...,  37.,  37., 176.],\n       [ nan,  nan,  nan, ..., 111., 111.,   5.],\n       [ nan,  nan,  nan, ...,  37.,  37.,   5.],\n       ...,\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan]], dtype=float32)Coordinates: (4)x(x)float64-97.39 -97.39 ... -95.86 -95.86axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([-97.393146, -97.39222 , -97.391294, ..., -95.860828, -95.859902,\n       -95.858977])y(y)float6439.72 39.72 39.72 ... 36.43 36.43axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([39.722234, 39.721308, 39.720382, ..., 36.428908, 36.427982, 36.427057])band()int641array(1)spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-97.39360889264871 0.0009258717165099349 0.0 39.7226968847078 0.0 -0.0009258717165099349array(0)Indexes: (2)xPandasIndexPandasIndex(Index([-97.39314595679046, -97.39222008507396, -97.39129421335744,\n       -97.39036834164094, -97.38944246992442, -97.38851659820791,\n        -97.3875907264914, -97.38666485477489, -97.38573898305839,\n       -97.38481311134187,\n       ...\n       -95.86730936798209, -95.86638349626558, -95.86545762454907,\n       -95.86453175283256, -95.86360588111604, -95.86268000939954,\n       -95.86175413768304, -95.86082826596652, -95.85990239425001,\n        -95.8589765225335],\n      dtype='float64', name='x', length=1658))yPandasIndexPandasIndex(Index([ 39.72223394884955,  39.72130807713304,  39.72038220541653,\n       39.719456333700016,  39.71853046198351,    39.717604590267,\n        39.71667871855049,  39.71575284683398,  39.71482697511747,\n        39.71390110340096,\n       ...\n        36.43538935523928,  36.43446348352277,  36.43353761180626,\n        36.43261174008975,  36.43168586837324,  36.43075999665673,\n        36.42983412494022,  36.42890825322371,   36.4279823815072,\n        36.42705650979069],\n      dtype='float64', name='y', length=3560))Attributes: (4)AREA_OR_POINT :AreaTIFFTAG_RESOLUTIONUNIT :1 (unitless)TIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1"
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#define-custom-colormap",
    "href": "notebooks/integrate_with_geopandas.html#define-custom-colormap",
    "title": "12  Integrate with GeoPandas",
    "section": "Define custom colormap",
    "text": "Define custom colormap\n\n# Define your labels and their corresponding colors\ninfo = cropland.getInfo()\n\nclass_names = info['properties']['cropland_class_names']\nclass_values = info['properties']['cropland_class_values']\nclass_colors = info['properties']['cropland_class_palette']\nclass_colors = ['#'+c for c in class_colors]\n\n\n# Create the colormap\ncmap = ListedColormap(class_colors)\n\n# Create a norm with boundaries\nnorm = BoundaryNorm(class_values, cmap.N)"
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#clip-and-save-cropland-map-for-each-polygon",
    "href": "notebooks/integrate_with_geopandas.html#clip-and-save-cropland-map-for-each-polygon",
    "title": "12  Integrate with GeoPandas",
    "section": "Clip and save cropland map for each polygon",
    "text": "Clip and save cropland map for each polygon\nIn this step we are clipping the cropland datalayer for each polygon and then saving that clipped and masked image into the GeoDataframe.\n\n# Check that the CRS are the same before clipping the layer\ngdf_patches.crs == raster.rio.crs\n\nTrue\n\n\n\n# Define a function to clip the raster with each polygon and return a numpy array\ndef clip_raster(polygon, raster):\n    \n    # Clip the raster with the polygon\n    clipped = raster.rio.clip([polygon.geometry], crs=raster.rio.crs, all_touched=True)\n    \n    return clipped\n\n\n# Apply the function to each row in the GeoDataFrame to create a new 'clipped_raster' column\ngdf_patches['clipped_raster'] = gdf_patches.apply(lambda row: clip_raster(row, raster), axis=1)\n\n# Inspect resulting GeoDataframe\ngdf_patches.head(3)\n\n\n\n\n\n\n\n\nBIOME_NAME\nBIOME_NUM\nCOLOR\nCOLOR_BIO\nCOLOR_NNH\nECO_BIOME_\nECO_ID\nECO_NAME\nLICENSE\nNNH\nNNH_NAME\nOBJECTID\nREALM\nSHAPE_AREA\nSHAPE_LENG\ngeometry\narea\nclipped_raster\n\n\n\n\n0\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116\nPOLYGON ((-95.99115 39.43608, -95.91121 39.396...\n4.267920e+08\n[[&lt;xarray.DataArray 'band_data' ()&gt;\\narray(143...\n\n\n1\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116\nPOLYGON ((-96.06161 38.08792, -96.05381 38.080...\n5.749008e+08\n[[&lt;xarray.DataArray 'band_data' ()&gt;\\narray(nan...\n\n\n2\nTemperate Grasslands, Savannas & Shrublands\n8\n#A87001\n#FEFF73\n#EE1E23\nNE08\n392\nFlint Hills tallgrass prairie\nCC-BY 4.0\n4\nNature Imperiled\n271\nNearctic\n2.873636\n9.461116\nPOLYGON ((-95.87537 37.82449, -95.88215 37.819...\n1.079830e+07\n[[&lt;xarray.DataArray 'band_data' ()&gt;\\narray(nan...\n\n\n\n\n\n\n\n\n# Create figure showing the cropland data layer for a selected polygon\nfig, ax = plt.subplots(figsize=(6, 6))\n\ngdf_patches.loc[[idx_largest_area],'geometry'].boundary.plot(ax=ax, edgecolor='k')\ngdf_patches.loc[idx_largest_area,'clipped_raster'].plot(ax=ax, cmap=cmap, \n                                                        norm=norm, add_colorbar=False)\nplt.show()"
  },
  {
    "objectID": "notebooks/integrate_with_geopandas.html#clip-all-fragmentated-areas-to-cropland-data-layer",
    "href": "notebooks/integrate_with_geopandas.html#clip-all-fragmentated-areas-to-cropland-data-layer",
    "title": "12  Integrate with GeoPandas",
    "section": "Clip all fragmentated areas to cropland data layer",
    "text": "Clip all fragmentated areas to cropland data layer\nThis process involves rasterizing each polygon to match the spatial resolution of the cropland data layer.\n\n# Define the transformation and shape from the raster metadata\ntransform = raster.rio.transform()\nshape = (raster.rio.height, raster.rio.width)\n\n# Rasterize the polygons\nrasterized_image = rasterize(\n    [(geometry, 1) for geometry in gdf_patches.geometry],\n    out_shape=shape,\n    fill=0,  # Background value for raster cells not covered by polygons\n    transform=transform,\n    all_touched=True  # Set to True if you want to include all pixels touched by geometries\n)\n\n# Convert the rasterized image to an xarray DataArray\nrasterized_da = xr.DataArray(rasterized_image, dims=(\"y\", \"x\"), coords=raster.coords)\n\n# Overlay the rasterized polygons on the raster by using the where method\n# This will mask the raster outside the polygons\nmasked_raster = raster.where(rasterized_da == 1)\n\n\n# Create figure showing the cropland data layer for all polygons\nfig, ax = plt.subplots(figsize=(10, 10))\nmasked_raster.plot(ax=ax, cmap=cmap, norm=norm, add_colorbar=False)\ngdf_patches.boundary.plot(ax=ax, edgecolor='k')\nplt.show()"
  },
  {
    "objectID": "notebooks/unsupervised_classification.html#example-1-washed-clustering",
    "href": "notebooks/unsupervised_classification.html#example-1-washed-clustering",
    "title": "13  Unsupervised classification",
    "section": "Example 1: Washed clustering",
    "text": "Example 1: Washed clustering\n\nLoad region from local file\nIn this tutorial we will use the Kings Creek watershed, which is fully contained withing the Konza Prairie Biological station. The watershed is dominated by a tallgrass vegetation and riparian areas surrounding the Kings Creek.\n\n# Open geoJSON file and store it in a variable\nwith open(\"../datasets/kings_creek.geojson\") as file:\n    kings_creek = json.load(file)\n    \n\n\n# Define GEE Geometry using local file\ngeom = ee.Geometry(kings_creek['features'][0]['geometry'])\n\n\n# Test GEE Geometry import printing the area in km^2\ngeom.area().getInfo()/1000000\n\n11.353858144557279\n\n\n\n\nPrepare clustering dataset\nThis step consists of reading images from different products, and then merging them into an image of multiple bands, where each band is one of the selected features for clustering.\n\n# Import individual layers\nweather = ee.Image(\"WORLDCLIM/V1/BIO\").select(['bio01', 'bio12']).resample('bicubic')\nsoil = ee.Image(\"projects/soilgrids-isric/sand_mean\").select('sand_0-5cm_mean').resample('bicubic')\nlandforms = ee.Image('CSP/ERGo/1_0/Global/ALOS_landforms').select('constant').resample('bicubic')\n\n# Merge layers as bands\ndataset = weather.addBands(soil).addBands(landforms)\n\n\n\nGenerate clusters\n\n# Select random points across the image in the defined region for training\nsample_points = dataset.sample(region=geom, scale=20, numPixels=1000)\n\n\n# Define number of cluster to classify\ncluster_number = 5\nclassificator = ee.Clusterer.wekaKMeans(cluster_number).train(sample_points)\n\n\n\nReduce image to vector\n\n# Generate the clusters for the whole region\nclusters = dataset.cluster(classificator).reduceToVectors(scale=20, geometry=geom).getInfo()\n\n\n\nInteractive plot\n\n# Create Folium Map\nm = folium.Map(location=[39.08648, -96.582], zoom_start=13)\n    \ncmap = get_cmap('Set1',n=cluster_number)\ncluster_layer = folium.GeoJson(clusters, name=\"Kings Creek\",\n                               style_function=lambda x:get_polygon_color(x,cmap))\ncluster_layer.add_to(m)\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nExport clusters as geoJSON\n\n# Inspect resulting clusters\n# pprint(clusters)\n\n\n# Save result to a geoJSON file\nwith open('outputs/output.json', 'w') as file:\n    json.dump(clusters, file)\n    \n\n\n\nExport clusters as GeoTIFF\n\n# Create mask\nmask = ee.Image.constant(1).clip(geom).mask()\n\n\n# Create image URL\nimage_url = dataset.cluster(classificator).mask(mask).getDownloadUrl({\n    'region': geom,\n    'scale':30,\n    'crs': 'EPSG:4326',\n    'format': 'GEO_TIFF'\n})\n\n\n# Request data using URL and save data as a new GeoTiff file\nresponse = requests.get(image_url)\nfilename = '../outputs/kings_creek_clusters.tif'\nwith open(filename, 'wb') as f:\n    f.write(response.content)\n  \n\n\n# Read GeoTiff file using the Xarray package\nraster = xr.open_dataarray(filename).squeeze()\n\n#fig, ax = plt.subplots(1,1,figsize=(6,5))\nraster.plot(cmap='Set2', figsize=(4,4), add_colorbar=False);"
  },
  {
    "objectID": "notebooks/unsupervised_classification.html#example-2-state-level-clustering",
    "href": "notebooks/unsupervised_classification.html#example-2-state-level-clustering",
    "title": "13  Unsupervised classification",
    "section": "Example 2: State-level clustering",
    "text": "Example 2: State-level clustering\nIn this tutorial we will identify macroregions across Kansas determined by climate and soil variables.\n\nLoad region\n\n# Read US states\nUS_states = ee.FeatureCollection(\"TIGER/2018/States\")\n\n# Select Kansas\nkansas = US_states.filter(ee.Filter.eq('NAME','Kansas'))\n\n\n\nPrepare clustering dataset\n\n# Import image layers\nppt = ee.ImageCollection('OREGONSTATE/PRISM/Norm91m').select('ppt').sum().resample('bicubic')\ntmean = ee.ImageCollection('OREGONSTATE/PRISM/Norm91m').select('tmean').mean().resample('bicubic')\nvpdmax = ee.ImageCollection('OREGONSTATE/PRISM/Norm91m').select('vpdmax').mean().resample('bicubic')\nsoil = ee.Image(\"projects/soilgrids-isric/sand_mean\").select('sand_0-5cm_mean').resample('bicubic')\n\n# Merge layers into a single dataset\ndataset = ppt.addBands(soil).addBands(tmean).addBands(vpdmax)\n\n\n\nGenerate clusters\n\n# Select random points across the image in the defined region for training\nsample_points = dataset.sample(region=kansas, scale=1000, numPixels=1000)\n\n\n# Define number of cluster to classify\ncluster_number = 9\nclassificator = ee.Clusterer.wekaKMeans(cluster_number).train(sample_points)\n\n\n\nReduce image to vectors\n\n# Generate the clusters for the whole region\nclusters = dataset.cluster(classificator).reduceToVectors(scale=1000, geometry=kansas).getInfo()\n\n\n\nInteractive plot\n\n# Create Folium Map\nm = folium.Map(location=[38.5, -98.5], zoom_start=7)\n\ncmap = get_cmap('Set1',n=cluster_number)\ncluster_layer = folium.GeoJson(clusters, name=\"Kansas\", \n                               style_function=lambda x:get_polygon_color(x,cmap))\ncluster_layer.add_to(m)\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nExport clusters as GeoTIFF\n\n# Create mask\nmask = ee.Image.constant(1).clip(kansas).mask()\n\n\n# Create image URL\nimage_url = dataset.cluster(classificator).mask(mask).getDownloadUrl({\n    'region': kansas.geometry(),\n    'scale':1000,\n    'crs': 'EPSG:4326',\n    'format': 'GEO_TIFF'\n})\n\n\n# Request data using URL and save data as a new GeoTiff file\nresponse = requests.get(image_url)\nfilename = '../outputs/kansas_clusters.tif'\nwith open(filename, 'wb') as f:\n    f.write(response.content)\n  \n\n\n# Read GeoTiff file using the Xarray package\nraster = xr.open_dataarray(filename).squeeze()\n\n#fig, ax = plt.subplots(1,1,figsize=(6,5))\nraster.plot(cmap='Set2', figsize=(8,3));"
  },
  {
    "objectID": "notebooks/supervised_classification.html#define-helper-functions",
    "href": "notebooks/supervised_classification.html#define-helper-functions",
    "title": "14  Supervised classification",
    "section": "Define helper functions",
    "text": "Define helper functions\n\n# Create helper functions\n\n# Get Color for different polygons\ndef get_polygon_color(polygon):\n    color_values = ['#7b3294', '#008837']\n    color = color_values[polygon['properties']['label']]\n    return {'fillColor':color, 'fillOpacity':0.8}\n    \n    \ndef maskS2clouds(image):\n    \"\"\"\n    Function to filter images by cloud percentage\n    \"\"\"\n    qa = image.select('QA60')\n    cloudBitMask = 1 &lt;&lt; 10 # bits 10\n    cirrusBitMask = 1 &lt;&lt; 11 # bits 11\n\n    # Both flags should be set to zero (clear sky conditions)\n    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n    return image.updateMask(mask)\n\n\n# Define auxiliary functions\ndef create_raster(ee_object, vis_params, name):\n    \"\"\"\n    Function that createst GEE map into raster for folium map\n    \"\"\"\n    raster = folium.raster_layers.TileLayer(ee_object.getMapId(vis_params)['tile_fetcher'].url_format,\n                       name=name,\n                       overlay=True,\n                       control=True,\n                       attr='Map Data &copy; &lt;a href=\"https://earthengine.google.com/\"&gt;Google Earth Engine&lt;/a&gt;')\n    return raster"
  },
  {
    "objectID": "notebooks/supervised_classification.html#load-region-boundaries",
    "href": "notebooks/supervised_classification.html#load-region-boundaries",
    "title": "14  Supervised classification",
    "section": "Load region boundaries",
    "text": "Load region boundaries\n\n# Import boundary for region of interest (roi)\nwith open('../datasets/kings_creek.geojson') as file:\n    roi_json = json.load(file)\n\n# Define the ee.Geometry\nroi_geom = ee.Geometry(roi_json['features'][0]['geometry'])"
  },
  {
    "objectID": "notebooks/supervised_classification.html#load-labeled-regions-for-training",
    "href": "notebooks/supervised_classification.html#load-labeled-regions-for-training",
    "title": "14  Supervised classification",
    "section": "Load labeled regions for training",
    "text": "Load labeled regions for training\nThese polygons were created manually by inspecting a satellite image and drawing over small portions of the watershed that were clearly with riparian and grassland vegetation. Here is an excellent tool to get you started: https://geojson.io\n\n# Import labeled regions for riparian and grassland areas.\nwith open('../datasets/riparian.geojson') as file:\n    riparian_json = json.load(file)\n\nwith open('../datasets/grassland.geojson') as file:\n    grassland_json = json.load(file)\n\n    \n# Define the ee.Geometry for each polygon\nriparian_geom = ee.Feature(riparian_json['features'][0]['geometry'])\ngrassland_geom = ee.Feature(grassland_json['features'][0]['geometry'])\n\n\n# Add class values to features\nriparian_geom = riparian_geom.set('land_cover', 0)\ngrassland_geom = grassland_geom.set('land_cover', 1)\n\n\n# Merge train dataset into a FeatureCollection\ntraining_regions = ee.FeatureCollection([riparian_geom, grassland_geom])"
  },
  {
    "objectID": "notebooks/supervised_classification.html#load-image-dataset",
    "href": "notebooks/supervised_classification.html#load-image-dataset",
    "title": "14  Supervised classification",
    "section": "Load image dataset",
    "text": "Load image dataset\nThis image will be used to detect riparian and grassland vegetation beyond the provided training regions.\n\n# Sentinel 2 multispectral instrument\nS2 = ee.ImageCollection('COPERNICUS/S2_SR').filterDate('2022-06-01', '2022-07-31')\nS2 = S2.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',10)).map(maskS2clouds)\n\n# Mean multispectral image for entire period\nimg = S2.mean().divide(10000).clip(roi_geom)\n\n\n# Select values from dataset for the training regions \ntraining_data = img.sampleRegions(collection=training_regions,\n                                  properties=['land_cover'], scale=30)\n\n\n# Train Random Forest algorithm\nntrees = 10\ntrained_classifier = ee.Classifier.smileRandomForest(ntrees).train(features=training_data,\n                                                       classProperty='land_cover',\n                                                       inputProperties=img.bandNames())\n\n\n# Classify the entire King's Creek Watershed\nclassified_img = img.classify(trained_classifier)\nclassified_vector = classified_img.reduceToVectors(scale=30, \n                                                   geometry=roi_geom).getInfo()"
  },
  {
    "objectID": "notebooks/supervised_classification.html#save-static-maps",
    "href": "notebooks/supervised_classification.html#save-static-maps",
    "title": "14  Supervised classification",
    "section": "Save static maps",
    "text": "Save static maps\nDownload vector and raster maps.\n\n# Save vector map to GeoJSON file\nfilename_classified_vector = '../outputs/classified_vector_kings_creek.tif'\nwith open(filename_classified_vector, 'w') as file:\n    # Convert dictionary to a GeoJSON string and save it\n    file.write(json.dumps(classified_vector))\n    \n    \n# Create raster of classified image in geoTIFF image\nclassified_img_url = classified_img.getDownloadUrl({\n    'region': roi_geom,\n    'scale':30,\n    'crs': 'EPSG:4326',\n    'format': 'GEO_TIFF'\n})\n\n# Request and save geoTIFF map\nresponse = requests.get(classified_img_url)\nfilename_classified_img = '../outputs/classified_kings_creek.tif'\nwith open(filename_classified_img, 'wb') as f:\n    f.write(response.content)\n\n# Create raster of classified image in geoTIFF image\ntruecolor_img_url = img.getDownloadUrl({\n    'region': roi_geom,\n    'scale':30,\n    'crs': 'EPSG:4326',\n    'format': 'GEO_TIFF',\n    'bands':['B4', 'B3', 'B2']\n})\n\n# Request and save geoTIFF map\nresponse = requests.get(truecolor_img_url)\nfilename_truecolor_img = '../outputs/truecolor_kings_creek.tif'\nwith open(filename_truecolor_img, 'wb') as f:\n    f.write(response.content)"
  },
  {
    "objectID": "notebooks/supervised_classification.html#create-static-figure",
    "href": "notebooks/supervised_classification.html#create-static-figure",
    "title": "14  Supervised classification",
    "section": "Create static figure",
    "text": "Create static figure\n\n# Read GeoTiff file using the Xarray package\nraster_classified = xr.open_dataarray(filename_classified_img).squeeze() # 2d image\nraster_truecolor = xr.open_dataarray(filename_truecolor_img)\n\n# COnvert vector layer to GeoDataframe\ngdf = gpd.GeoDataFrame.from_features(classified_vector['features'], crs=4326)\ngdf.head(3)\n\n\n\n\n\n\n\n\ngeometry\ncount\nlabel\n\n\n\n\n0\nPOLYGON ((-96.55425 39.09019, -96.55344 39.090...\n3\n0\n\n\n1\nPOLYGON ((-96.55398 39.08776, -96.55398 39.087...\n77\n0\n\n\n2\nPOLYGON ((-96.55452 39.08965, -96.55452 39.089...\n5\n0\n\n\n\n\n\n\n\n\nfig,(ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8,4))\nfig.subplots_adjust(wspace=0.35)\n\nraster_classified.plot.imshow(ax=ax1, cmap='Set1', add_colorbar=False);\nax1.set_title('Classified image')\nax1.axis('equal')\n\nraster_truecolor.plot.imshow(ax=ax2);\nax2.set_title('True color image')\nax2.axis('equal')\n\nidx_riparian = gdf['label'] == 0 # select rows for riparian areas\ngdf.loc[idx_riparian].plot(ax=ax2, facecolor=(0.9,0.2,0,0.75), \n                           edgecolor='k', linewidth=0.5)\n\n\nplt.show()"
  },
  {
    "objectID": "notebooks/supervised_classification.html#interactive-map",
    "href": "notebooks/supervised_classification.html#interactive-map",
    "title": "14  Supervised classification",
    "section": "Interactive map",
    "text": "Interactive map\n\n# Create Folium Map\nm = folium.Map(location=[39.09, -96.592], zoom_start=13)\n\n# Create vector layer of classified polygons\ncluster_layer = folium.GeoJson(classified_vector, \n                             name=\"Classified image with RF\",\n                             style_function=get_polygon_color)\n\n\n# Visualization parameters of true color image\n# B4=Red, B3=Green, B2=Blue\nvis_params = {'min': 0.0, 'max': 0.3, 'bands': ['B4', 'B3', 'B2'], }\n\n\n# Create raster layer of true color image\ntrue_color_layer = folium.raster_layers.TileLayer(img.getMapId(vis_params)['tile_fetcher'].url_format,\n                       name='True color',\n                       overlay=True,\n                       control=True,\n                       attr='Map Data &copy; &lt;a href=\"https://earthengine.google.com/\"&gt;Google Earth Engine&lt;/a&gt;')\n\n# Add layers to interactive map\ntrue_color_layer.add_to(m)\ncluster_layer.add_to(m)\n\n# Add map controls to be able to compare \n# the true color image with the clasified layer\nfolium.LayerControl().add_to(m)\n\n# Render map\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "notebooks/export_data.html#select-region-for-tutorial",
    "href": "notebooks/export_data.html#select-region-for-tutorial",
    "title": "15  Export data",
    "section": "Select region for tutorial",
    "text": "Select region for tutorial\n\n# Read US watersheds using hydrologic unit codes (HUC)\nwatersheds = ee.FeatureCollection(\"USGS/WBD/2017/HUC12\")\nmcdowell_creek = watersheds.filter(ee.Filter.eq('huc12', '102701010204')).first()\nwatershed_point = ee.Geometry.Point([-96.556316, 39.084535])\n\n# Create mask for the region\nmask = ee.Image.constant(1).clip(mcdowell_creek).mask()"
  },
  {
    "objectID": "notebooks/export_data.html#raster-data",
    "href": "notebooks/export_data.html#raster-data",
    "title": "15  Export data",
    "section": "Raster data",
    "text": "Raster data\n\nSave geotiff image\nIn this example we will request a small georeferenced image and then save it in .geotiff format. We will also read the image back into the notebook.\n\n# Import map from Digital Elevation Model (DEM)\nsrtm = ee.Image('CGIAR/SRTM90_V4')\n\n\n# Clip elevation map to boundaries of McDowell Creek\n# and mask points outside the watershed boundary\nmcdowell_creek_elv = srtm.clip(mcdowell_creek).mask(mask)\n\n\n# Define coordinate reference system\ncrs = 32614 # UTM14 Projected coordinates in meters\n#crs = 4326 # WGS84 Geographic coordinates in degrees\n\n\n# Get URL link to full image\nimage_url = mcdowell_creek_elv.getDownloadUrl({\n    'region': mcdowell_creek.geometry(),\n    'scale':30,\n    'crs': f'EPSG:{crs}',\n    'format': 'GEO_TIFF'\n})\n\n# Display clickable URL link to download TIFF image\nprint(image_url)\n\nhttps://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/a3c4c75d3ef68b3a9f43b5b1f66fab2a-8e5a43ff7247a0f523a367d9e6d98265:getPixels\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf we request the image using \"scale: 1\", meaning that we want an image with each pixel representing 1 square meter, then for this particular watershed ww will get the following error message: \"Total request size (691287720 bytes) must be less than or equal to 50331648 bytes.\", which means that we are requesting too much data. To solve this issue we need to reduce the number of pixels by re-scaling the image so that we to meet the quota allowed by GEE.\n\n\n\n# Request data using URL and save data as a new GeoTiff file\nresponse = requests.get(image_url)\n\n# Write file to disk\nfilename = '../outputs/mc_dowell_creek_elevation.tif'\nwith open(filename, 'wb') as f:\n    f.write(response.content)\n    \n\n\n# Read GeoTiff file using the Xarray package\nraster = xr.open_dataarray(filename).squeeze()\n\n\n# Create a figure\nraster.plot(cmap='magma', cbar_kwargs={'label':'Elevation m'});\nplt.title('Kings Creek Elevation Map')\nplt.xlabel('Easting (meters)')\nplt.ylabel('Northing (meters)')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nIn-memory GeoTiff\nSometimes we simply want to retrieve an image and plot it, without necessarily saving it into our local drive.\nIf the code below does not work, try installating the rioxarray package using !pip install rioxarray, which extends xarray and allows it to use the rasterio engine to read bytes file.\n\n# Open temporary file in memory, save the content \n# of the request (this is the geotiff image) in a temporary file,\n# then read the temporary file and plot the map.\nwith io.BytesIO(response.content) as memory_file:\n    raster = xr.open_dataarray(memory_file, engine='rasterio').squeeze()\n    \n    # Create plot while the file is open\n    raster.plot(cmap='inferno', cbar_kwargs={'label':'Elevation m'});\n    plt.title('Kings Creek Elevation Map')\n    plt.xlabel('Easting (meters)')\n    plt.ylabel('Northing (meters)')\n    plt.tight_layout()\n    plt.show()\n    \n\n\n\n\n\n\nHandy function to save GeoTiffs\nSince this is a common operation, let’s wrap the code we wrote above into a function.\n\ndef save_geotiff(ee_image, filename, crs, scale, geom):\n    \"\"\"\n    Function to save images from Google Earth Engine into local hard drive.\n    \"\"\"\n    image_url = ee_image.getDownloadUrl({\n    'region': geom,\n    'scale':scale,\n    'crs': f'EPSG:{crs}',\n    'format': 'GEO_TIFF'})\n    \n    # Request data using URL and save data as a new GeoTiff file\n    response = requests.get(image_url)\n    with open(filename, 'wb') as f:\n        f.write(response.content)\n        return print(f'Image {filename} saved.')\n    \n\n\n\nGet Numpy array\nSometimes instead of the georeferenced image we want the raw data in the form of a Numpy array, so that we can further process the data in Python.\n\n# Use the requests method to read image\nnumpy_array_url = mcdowell_creek_elv.getDownloadUrl({'crs': f'EPSG:{crs}',\n                                                     'scale':30,\n                                                     'format': 'NPY'})\nresponse = requests.get(numpy_array_url )\nelev_array = np.load(io.BytesIO(response.content), encoding='bytes').astype(np.float64)\nprint(elev_array)\n\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n\n\n\n# Convert zero values in the mask to NaN\nidx_zero = elev_array == 0\nelev_array[idx_zero] = np.nan\n\n# Create histogram of elevation\nplt.figure(figsize=(5,4))\nplt.hist(elev_array.flatten(), \n         bins='scott', \n         facecolor='lightblue', edgecolor='k');\nplt.xlabel('Elevation (m)')\nplt.ylabel('Density')\nplt.show()\n\n\n\n\n\nprint('Array dimensions:', elev_array.shape)\nprint('Total pixels:', elev_array.size)\n\nArray dimensions: (496, 401)\nTotal pixels: 198896\n\n\n\n\nSave thumbnail image\nA thumbnail image is good for display purposes. This is not the actual, high-resolution image. This image does not have any elevation data or geographic coordinates. The color of each pixel was assigned according to the colormap and range of values provided when requesting the thumbnail image.\n\n# Create the url associated to the Image you want\ncmap = [rgb2hex(c) for c in plt.get_cmap('magma').colors]\nthumbnail_url = mcdowell_creek_elv.getThumbUrl({'min': 300,\n                                      'max': 450,\n                                      'dimensions': 512,\n                                      'palette': cmap})\n\n# Print URL\nprint(thumbnail_url)\n\nhttps://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/f766af93b23eddb9c6dfc16a16b2dc33-8904153edffc111c602c82500a6f915f:getPixels\n\n\n\n# Display a thumbnail of elevation map\nresponse = requests.get(thumbnail_url )\nimg = plt.imread(io.BytesIO(response.content))\nplt.imshow(img, cmap='magma')\nplt.axis('off')\nplt.savefig('../outputs/kings_creek_thumbnail.jpg')\nplt.show()"
  },
  {
    "objectID": "notebooks/export_data.html#vector-data",
    "href": "notebooks/export_data.html#vector-data",
    "title": "15  Export data",
    "section": "Vector data",
    "text": "Vector data\n\nGet Feature coordinates into Pandas DataFrame\nIn this example we will simply access the latitude and longitude fields of a Kansas county.\n\n# US Counties dataset\nUS_counties = ee.FeatureCollection(\"TIGER/2018/Counties\") \n\n# '20161' is the ID for Riley county in Kansas\ncounty = US_counties.filter(ee.Filter.eq('GEOID','20161'))\n\n# Get coordinates of the county geometryand put them in a dataframe for easy data handling.\ndf = pd.DataFrame(county.first().getInfo()['geometry']['coordinates'][0])\ndf.columns = ['lon','lat']\ndf.head()\n\n\n\n\n\n\n\n\nlon\nlat\n\n\n\n\n0\n-96.961683\n39.220095\n\n\n1\n-96.961369\n39.220095\n\n\n2\n-96.956566\n39.220005\n\n\n3\n-96.954188\n39.220005\n\n\n4\n-96.952482\n39.220005\n\n\n\n\n\n\n\n\n\nSave data in tabular format\nIn this example the goal is to request temporal soil moisture data, convert it into a Pandas DataFrame, and then save it as a comma-separated value file.\n\n# Load SMAP product (3-hour resolution)\nsmap = ee.ImageCollection(\"NASA/SMAP/SPL4SMGP/007\").filterDate('2018-01-01','2018-01-31')\n\n# Select rootzone soil moisture band\nsm_rootzone = smap.select('sm_rootzone')\n\n# Get rootzone soil moisture for watershed point\nwatershed_sm = sm_rootzone.getRegion(watershed_point, scale=1).getInfo()\n\n\n# Convert output into a Pandas Dataframe\ndf = pd.DataFrame(watershed_sm[1:])\ndf.columns = watershed_sm[0]\ndf['time'] = pd.to_datetime(df['time'], unit='ms')\ndf.head(3)\n\n\n\n\n\n\n\n\nid\nlongitude\nlatitude\ntime\nsm_rootzone\n\n\n\n\n0\n20180101_0130\n-96.556312\n39.084535\n2018-01-01 01:30:00\n0.297576\n\n\n1\n20180101_0430\n-96.556312\n39.084535\n2018-01-01 04:30:00\n0.297541\n\n\n2\n20180101_0730\n-96.556312\n39.084535\n2018-01-01 07:30:00\n0.297562\n\n\n\n\n\n\n\n\n# Save Dataframe to local drive\ndf.to_csv('../outputs/smap_rootzone_2018.csv', index=False)\n\n\n# Create figure to visualize data\ndate_fmt = mpd.ConciseDateFormatter(mpd.AutoDateLocator())\nplt.figure(figsize=(6,3))\nplt.title('Kings Creek Watershed')\nplt.plot(df['time'], df['sm_rootzone']*100)\nplt.ylabel('Volumetric water content (%)')\nplt.gca().xaxis.set_major_formatter(date_fmt)\nplt.show()\n\n\n\n\n\n\nSave Feature as geoJSON\nWe will save a polygon feature representing the boundary of the McDowell Creek small watershed in central Kansas as a geoJSON file.\n\n# Convert the feature to a GeoJSON string\nfeature_info = mcdowell_creek.getInfo()  # Retrieves the information about the feature\n\n# Save the GeoJSON string to a file\nwith open('../outputs/kings_creek_from_gee.geojson', 'w') as file:\n    # Convert dictionary to a GeoJSON string and save it\n    file.write(json.dumps(feature_info))\n    \n\nIn this example we will save the boundary of the state of Kansas.\n\n# Read US states\nUS_states = ee.FeatureCollection(\"TIGER/2018/States\")\n\n# Select Kansas\nstate = US_states.filter(ee.Filter.inList('NAME',['Kansas']))\n\n# Retrieves the information about the feature\nstate_info = state.getInfo()  \n\n# Save the GeoJSON string to a file\nwith open('../outputs/kansas_bnd_from_gee.geojson', 'w') as file:\n    \n    # Convert dictionary to a GeoJSON string and save it\n    file.write(json.dumps(feature_info))\n\n\n\nSave FeatureCollection as shapefile\nThis section requires the GeoPandas library.\n\n# Import GeoPandas\nimport geopandas as gpd\n\n\n# Convert FeatureCollection to GeoDataFrame\ngdf = gpd.GeoDataFrame.from_features([feature_info])\n\n# Create a figure to quickly inspect the dataset\ngdf.plot(facecolor='None');\n\n\n\n\n\n# Save as shapefile\ngdf.to_file('../outputs/kings_creek_from_gee.shp', index=False)\n\n\n# Save as geojson using GeoPandas\ngdf.to_file('../outputs/kings_creek_from_gee.geojson', driver='GeoJSON', index=False)  \n\n\n\nSave FeatureCollection as shapefile (Advanced)\nIn this case we will save a FeatureCollection with Polygon features and with GeometryCollection features, which are not supported by shapefiles. So we will need to iterate over each geometry, and only select polygons for those geometries that contain other features, like Points or LineStrings. Using geojson is recommended in this case to avoid the extra processing to fit the specifications of ESRI Shapefiles.\nIdeally all the counties should be Polygons, but sometimes geometries bordering rivers or other states can result in GeometryCollections.\n\n# Read US counties and filter bounds for selected region\ncounties = ee.FeatureCollection(\"TIGER/2018/Counties\")\n\n# Get FeatureCollection data\n# Kansas has STATEFP number equal to 20\ncounties_data = counties.filter(ee.Filter.eq('STATEFP','20')).getInfo()\n\n\n# Define coordinate reference system\nwgs84 = 4326 # World Geodetic System 1984\n\n# Convert FeatureCollection to GeoDataFrame\ngdf_counties = gpd.GeoDataFrame.from_features(counties_data, crs=wgs84)\ngdf_counties.head(3)\n\n\n\n\n\n\n\n\ngeometry\nALAND\nAWATER\nCBSAFP\nCLASSFP\nCOUNTYFP\nCOUNTYNS\nCSAFP\nFUNCSTAT\nGEOID\nINTPTLAT\nINTPTLON\nLSAD\nMETDIVFP\nMTFCC\nNAME\nNAMELSAD\nSTATEFP\n\n\n\n\n0\nPOLYGON ((-97.15333 37.47553, -97.15329 37.474...\n2915648163\n17322935\n11680\nH1\n035\n00484987\n556\nA\n20035\n+37.2345068\n-096.8372468\n06\n\nG4020\nCowley\nCowley County\n20\n\n\n1\nPOLYGON ((-97.15347 37.82517, -97.15342 37.824...\n3702816810\n43671391\n48620\nH1\n015\n00484977\n556\nA\n20015\n+37.7736487\n-096.8388402\n06\n\nG4020\nButler\nButler County\n20\n\n\n2\nPOLYGON ((-97.80760 37.47387, -97.80755 37.472...\n3060429574\n8589030\n48620\nH1\n191\n00481812\n556\nA\n20191\n+37.2366617\n-097.4933519\n06\n\nG4020\nSumner\nSumner County\n20\n\n\n\n\n\n\n\n\n# Find if we have features that are not polygons\ngdf_counties[gdf_counties.geometry.type != 'Polygon']\n\n\n\n\n\n\n\n\ngeometry\nALAND\nAWATER\nCBSAFP\nCLASSFP\nCOUNTYFP\nCOUNTYNS\nCSAFP\nFUNCSTAT\nGEOID\nINTPTLAT\nINTPTLON\nLSAD\nMETDIVFP\nMTFCC\nNAME\nNAMELSAD\nSTATEFP\n\n\n\n\n46\nGEOMETRYCOLLECTION (LINESTRING (-96.52551 36.9...\n1654694134\n15243776\n\nH1\n019\n00484979\n\nA\n20019\n+37.1542592\n-096.2453962\n06\n\nG4020\nChautauqua\nChautauqua County\n20\n\n\n64\nGEOMETRYCOLLECTION (LINESTRING (-98.34961 37.3...\n2075290355\n3899269\n\nH1\n077\n00485004\n\nA\n20077\n+37.1881840\n-098.0665901\n06\n\nG4020\nHarper\nHarper County\n20\n\n\n99\nGEOMETRYCOLLECTION (LINESTRING (-94.87632 39.7...\n1019105692\n12424173\n41140\nH1\n043\n00484991\n312\nA\n20043\n+39.7885021\n-095.1472253\n06\n\nG4020\nDoniphan\nDoniphan County\n20\n\n\n\n\n\n\n\n\n# Let's inspect one of them to see what's inside\n# Here we have a LineString and a Polygon. \nlist(gdf_counties.loc[46,'geometry'].geoms)\n\n# The shapefile will not be able to save this. Let's retain the polygon only\n\n[&lt;LINESTRING (-96.526 36.999, -96.526 36.999)&gt;,\n &lt;POLYGON ((-96.526 37.028, -96.526 37.016, -96.526 37.016, -96.526 37.008, -...&gt;]\n\n\n\n# Iterate over each row. Here we assume that there is \n# only one polygon in each row that has a GeometryCollection.\nfor k,row in gdf_counties.iterrows():\n    \n    # Check if row geometry is 'GeometryCollection'\n    if row['geometry'].geom_type == 'GeometryCollection':\n        \n        # Iterate over each component of the GeometryCollection\n        for geom in list(row['geometry'].geoms):\n            \n            # Overwrite geometry of row with polygon\n            if geom.geom_type == 'Polygon':\n                gdf_counties.loc[k,'geometry'] = geom\n                \n# For multiple polygons you can keep the largest one using \n# something like: max(polygons, key=lambda a: a.area)\n\n\n# Check that we don't have any rows left that is not a polygon\n# Returned GeoDataFrame should be empty\ngdf_counties[gdf_counties.geometry.type != 'Polygon']\n\n\n\n\n\n\n\n\ngeometry\nALAND\nAWATER\nCBSAFP\nCLASSFP\nCOUNTYFP\nCOUNTYNS\nCSAFP\nFUNCSTAT\nGEOID\nINTPTLAT\nINTPTLON\nLSAD\nMETDIVFP\nMTFCC\nNAME\nNAMELSAD\nSTATEFP\n\n\n\n\n\n\n\n\n\n\n# Plot counties to ensure we have all of them\ngdf_counties.plot(facecolor='None');\n\n\n\n\n\n# Now we can save the GeoDataframe as a Shapefile\ngdf_counties.to_file('../outputs/kansas_counties_from_gee.shp', index=False)"
  },
  {
    "objectID": "notebooks/interactive_maps.html#define-some-helper-functions",
    "href": "notebooks/interactive_maps.html#define-some-helper-functions",
    "title": "16  Interactive maps",
    "section": "Define some helper functions",
    "text": "Define some helper functions\nLet’s define some functions to avoid repeating the following code everytime we want to create a raster image or every time we want to specify a given colormap for our map.\n\ndef get_raster_map(ee_object, vis, name):\n    \"\"\"\n    Function that retrieves raster map from GEE and applies some style.\n    \"\"\"\n    if isinstance(ee_object, ee.Image):\n        layer = folium.TileLayer(ee_object.getMapId(vis)['tile_fetcher'].url_format,\n                           name=name,\n                           overlay=True,\n                           control=True,\n                           attr='Map Data &copy; &lt;a href=\"https://earthengine.google.com/\"&gt;Google Earth Engine&lt;/a&gt;')\n        \n    return layer\n\n\n\ndef get_vector_map(ee_object,vis,name):\n    \"\"\"\n    Function that retrieves vector map from GEE and applies some style.\n    \"\"\"\n    if isinstance(ee_object, ee.FeatureCollection):\n        layer = folium.GeoJson(ee_object.getInfo(),\n                               name=name,\n                               style_function=lambda feature: {\n                                   'fillColor': vis['face_color'],\n                                   'color': vis['edge_color'],\n                                   'weight': vis['line_width']})\n    return layer\n\n\n\n# Authenticate GEE (follow the link and copy-paste the token in the notebook)\n#ee.Authenticate()\n\n# Initialize the library.\nee.Initialize()"
  },
  {
    "objectID": "notebooks/interactive_maps.html#state-land-cover",
    "href": "notebooks/interactive_maps.html#state-land-cover",
    "title": "16  Interactive maps",
    "section": "State land cover",
    "text": "State land cover\n\n# Read US states\nUS_states = ee.FeatureCollection(\"TIGER/2018/States\")\n\n# Select Kansas\nregion = US_states.filter(ee.Filter.inList('NAME',['Kansas']))\n\n\n# Land use for 2021\nland_use = ee.ImageCollection('USDA/NASS/CDL')\\\n             .filter(ee.Filter.date('2020-01-01', '2021-12-31')).first().clip(region)\n\n# Select cropland layer\ncropland = land_use.select('cropland')\n\n\n# Get layer metadata\ninfo = cropland.getInfo()\n\n# Remove comment to print the entire information (output is long!)\n# print(info)\nprint(info.keys())\n\ndict_keys(['type', 'bands', 'id', 'version', 'properties'])\n\n\n\n# Get land cover names, values, and colors from metadata\n\nclass_names = info['properties']['cropland_class_names']\nclass_values = info['properties']['cropland_class_values']\nclass_colors = info['properties']['cropland_class_palette']\n\n\n# Create dictionary to easily access properties by land cover name\nclass_props = {}\nfor k,name in enumerate(class_names):\n    class_props[name] = {'value':class_values[k], 'color':class_colors[k]}\n\n# Print example\nclass_props['Corn']\n\n{'value': 1, 'color': 'ffd300'}\n\n\n\n# Create self masks for each land cover, so that only \n# the pixels for this land cover visible\n\ncorn = cropland.eq(class_props['Corn']['value']).selfMask()\nsorghum = cropland.eq(class_props['Sorghum']['value']).selfMask()\nsoybeans = cropland.eq(class_props['Soybeans']['value']).selfMask()\nwheat = cropland.eq(class_props['Winter Wheat']['value']).selfMask()\ngrassland = cropland.eq(class_props['Grassland/Pasture']['value']).selfMask()\n\n\n\n\n\n\n\nTip\n\n\n\nSince we created a dictionary using the name of the land cover class as the key, in the previous cell you can use Tab-autocompletion.\n\n\n\n# Initialize map centered at a specific location and zoom level\nm = folium.Map(location=[38, -98], zoom_start=7)\n\nget_raster_map(corn, {'palette':[class_props['Corn']['color']]}, 'Corn').add_to(m)\nget_raster_map(sorghum, {'palette':[class_props['Sorghum']['color']]}, 'Sorghum').add_to(m)\nget_raster_map(soybeans, {'palette':[class_props['Soybeans']['color']]}, 'Soybeans').add_to(m)\nget_raster_map(wheat, {'palette':[class_props['Winter Wheat']['color']]}, 'Wheat').add_to(m)\nget_raster_map(grassland, {'palette':[class_props['Grassland/Pasture']['color']]}, 'Grassland').add_to(m)\n\n# Add vector layers\nget_vector_map(region, vis={'face_color':'#00FFFF00',\n                     'edge_color':'black',\n                     'line_width':2}, name='State boundary').add_to(m)\n\nget_vector_map(counties, vis={'face_color':'#00FFFF00',\n                     'edge_color':'grey',\n                     'line_width':1}, name='County boundary').add_to(m)\n\n\n# Add a layer control panel to the map.\nm.add_child(folium.LayerControl())\n\n# Display the map.\ndisplay(m)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  }
]